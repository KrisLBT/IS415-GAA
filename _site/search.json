[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, I will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#st_geometry",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "st_geometry()",
    "text": "st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#glimpse",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "glimpse()",
    "text": "glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#head",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "head()",
    "text": "head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#basic-plotting",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#basic-plotting",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Basic Plotting",
    "text": "Basic Plotting\n\nplot(mpsz)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-st_geometry",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Plotting st_geometry()",
    "text": "Plotting st_geometry()\n\nplot(st_geometry(mpsz))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-specific-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-specific-attribute",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Plotting specific attribute",
    "text": "Plotting specific attribute\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-dataframe",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Assigning EPSG code to a simple feature dataframe",
    "text": "Assigning EPSG code to a simple feature dataframe\n###Seeing the CRS\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nSetting the CRS to 3414\n\nmpsz3414 <- st_set_crs(mpsz, 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#check-the-crs-again",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#check-the-crs-again",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Check the CRS again",
    "text": "Check the CRS again\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#check-the-geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#check-the-geometry",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Check the geometry",
    "text": "Check the geometry\nFirstly, I will check the projection for preschool\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transform",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transform",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Transform",
    "text": "Transform\nThen, I will transform the CRS\n\npreschool3414 <- st_transform(preschool, \n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#display-the-new-crs",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#display-the-new-crs",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Display the new CRS",
    "text": "Display the new CRS\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reading-the-csv-file",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reading-the-csv-file",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Reading the csv file",
    "text": "Reading the csv file\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reading-the-listings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reading-the-listings",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Reading the listings",
    "text": "Reading the listings\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    <dbl> <chr>       <dbl> <chr>     <chr>               <chr>            <dbl>\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude <dbl>, room_type <chr>, price <dbl>,\n#   minimum_nights <dbl>, number_of_reviews <dbl>, last_review <date>,\n#   reviews_per_month <dbl>, calculated_host_listings_count <dbl>,\n#   availability_365 <dbl>, number_of_reviews_ltm <dbl>, license <chr>"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#convert-the-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#convert-the-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Convert the simple feature data frame from an aspatial data frame",
    "text": "Convert the simple feature data frame from an aspatial data frame\n\nlistings_sf <- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#examine-contents",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#examine-contents",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Examine contents",
    "text": "Examine contents\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             <dbl> 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           <chr> \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        <dbl> 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      <chr> \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            <chr> \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  <chr> \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 <dbl> 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              <dbl> 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    <date> 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              <dbl> 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count <dbl> 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               <dbl> 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        <chr> NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       <POINT [m]> POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\n\nComputing the 5-metres buffers around cycling paths\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\n\n\nCalculating area\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\n\n\nDerive total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#calculate-number-of-preschools-that-fall-insde-each-planning-subzone",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#calculate-number-of-preschools-that-fall-insde-each-planning-subzone",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Calculate number of preschools that fall insde each planning subzone",
    "text": "Calculate number of preschools that fall insde each planning subzone\n\nmpsz3414$'PreSch Count'<- lengths(st_intersects(mpsz3414, preschool3414))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#summary-of-the-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#summary-of-the-count",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Summary of the Count",
    "text": "Summary of the Count\n\nsummary(mpsz3414$'PreSch Count')\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#subzone-with-the-highest-number-of-pre-schools-ak-prof-about-wt-problem",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#subzone-with-the-highest-number-of-pre-schools-ak-prof-about-wt-problem",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Subzone with the highest number of pre-schools (ak prof about wt problem)",
    "text": "Subzone with the highest number of pre-schools (ak prof about wt problem)\n\ntop_n(mpsz3414, 1)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#derive-area-of-each-planning-subzone",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#derive-area-of-each-planning-subzone",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Derive area of each planning subzone",
    "text": "Derive area of each planning subzone\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#compute-density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#compute-density",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Compute density",
    "text": "Compute density\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-of-density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram-of-density",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Histogram of Density",
    "text": "Histogram of Density\n\nhist(mpsz3414$`PreSch Density`)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#are-pre-schools-even-distributed-in-singapore",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#are-pre-schools-even-distributed-in-singapore",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Are pre-schools even distributed in Singapore?",
    "text": "Are pre-schools even distributed in Singapore?\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#relationship-between-pre-school-density-and-pre-school-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#relationship-between-pre-school-density-and-pre-school-count",
    "title": "Hands-on Exercise 01: Geospatial Data Wrangling with R",
    "section": "Relationship between Pre-School Density and Pre-school Count",
    "text": "Relationship between Pre-School Density and Pre-school Count\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, I will be creating chloropleth maps using an R package called tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-the-packages-in-rstudio",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-the-packages-in-rstudio",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "Loading the packages in RStudio",
    "text": "Loading the packages in RStudio\n\npacman::p_load(sf,tmap,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#the-data-used",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#the-data-used",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "The Data Used",
    "text": "The Data Used\nThe following datasets will be used:\n\nMaster Plan 2014 Subzone Boundary (Web) from https://data.gov.sg\nSingapore Residents by Planning Area / Subzon, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format from Department of Statistics, Singapore https://www.singstat.gov.sg/"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "Importing Geospatial Data into R",
    "text": "Importing Geospatial Data into R\nUse the st_read() function of the sf package to import the subzone shapefile into R as a simple feature dataframe called mpsz\n\nmpsz <- st_read(dsn=\"data/geospatial\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nI can examine the content of mpsz wiith the following code chunk\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "Importing Attribute Data into R",
    "text": "Importing Attribute Data into R\nNext, I will import attribute data and save the file into an R dataframe called popdata\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore a thematic map can be prepared, I will have to prepare a data table with 2020 values. It will include the following variables:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the Attribute Data\nBefore we can perform the georelational join, 1 extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ are made up of lower- and uppercase while SUBZONE_N and PLN_AREA_N are in uppercase\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nNext, the left_join_ of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020, \n                          by = c(\"SUBZONE_N\"= \"SZ\"))\n\nNext, I will write an rds:\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-chloropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-chloropleth-map-quickly-by-using-qtm",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "Plotting a Chloropleth Map Quickly by Using qtm()",
    "text": "Plotting a Chloropleth Map Quickly by Using qtm()\nThe code chunk will draw a cartographic standard chloropleth map as shown below:\n\ntmap_mode(\"plot\")\n\nqtm(mpsz_pop2020,\n    fill=\"DEPENDENCY\")\n\n\n\n\nLearning points:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, the “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 02: Thematic Mapping and GeoVisualisation with R",
    "section": "Creating a Choropleth Map by Using tmap’s Elements",
    "text": "Creating a Choropleth Map by Using tmap’s Elements\nWhle gtm() is very fast and easy, the disadvatage is that the aesthetics of individual layers are difficult to control. To draw a high quality cartographic chloropleth map, tmap’s drawing elements should be used\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nThe following sections will break down the code and explain what each individual element does.\n\nDrawing the Base Layer\nThe basic building block of tmap is tm_shape() followed by one or more elements such as tm_fill() and tm_polygons()\nIn the code chunk below, tm_shape() is used to define the input data and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\nDrawing a Map with tm_polygons()\nTo draw a chloropleth map showing a the geographical distribution of a selected variable by planning subzone, I assign the target variable such as DEPENDENCY to tm_polygons()\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the chloropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a Map Using tm_fill() and tm_border()\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the chloropleth map.\nThe following code chunk draws a chloropleth map using tm_fill() alone\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nTo add the boundaries of the planning subzones, tm_borders() will be used:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\nData Classificiation Methods of tmap\nMost chloropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nUsing Built-in Classification Methods\nThe code chunk below shows a quantile data classficiation that uses 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY\n\nDifferent Classfication Methods\nIn the code chunk below, kmeans data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, hclust data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, bclust data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\nDifferent Number of Classes\nWith n = 5\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWith n = 10\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWith n = 15\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 15,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWith n = 20\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nPlotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nit is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, I will plot the chLoropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package\n\nUsing ColorBrewer palette\nTo change the colour, I assign the preferred colour to the palette argument of tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTo reverse the colour scheme, add an “-” behind the palette value as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMap Layout\nMap layout refers to the combination of all map elements into a cohesive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\nCartographic funiture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines respectively onto the chloropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset to the default style, refer to the code chunk below:\n\ntmap_style(\"white\")\n\n\n\nDrawinig Facet Chloropleth Maps\nFacet maps are composed of many maps arranged side-by-side and occassionally, vertically. They enable the visualisation of how spatial relationships shift with respect to another variable.\nIn tmap, this can be done in 3 ways:\n\nby assigning multiple values to at least one of the aesthetic arguments,\nby defining a group-by variable in tm_facets() and,\nby creating multiple stand-alone maps with tmap_arrange()\n\n\nBy Assigning Multiple Values to At Least One of the Aesthetic Arguments\nIn the code chunk below, small chloropleth maps are created by defining ncols in tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nBy Defining a Group-by Variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nBy Creating Multiple Stand-alone Maps with tmaps_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating facets maps, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3 and 4",
    "section": "",
    "text": "In this exercse, we will be learning about 1st order Spatial Point Patterns Analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#the-data",
    "title": "Hands-on Exercise 3 and 4",
    "section": "The Data",
    "text": "The Data\nThe following datasets will be used\n\nCHILDCARE which was downloaded from data.gov.sg\n2014 Master Plan Subzone Boundary (No Sea) which was downloaded from data.gov.sg\nCoastalOutline, which was derived from 2019 Master Plan Subzone Boundary (No Sea). It was downloaded from data.gov.sg"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#downloading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#downloading-packages",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Downloading Packages",
    "text": "Downloading Packages\nThe following packages will be used:\n\nmaptools\nsf\nraster\nspatstat\ntmap\n\n\n\nShow the code\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\n\nAs there may be issues with installing maptools, you may use the following:\n\n\nShow the code\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-spatial-data",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Importing the Spatial Data",
    "text": "Importing the Spatial Data\nImport the spatial data using st_read().\n\n\nShow the code\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nShow the code\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nShow the code\nsg_sf <-\n  st_read(dsn=\"data\",\n          layer= \"CostalOutline\")\n\n\nReading layer `CostalOutline' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class-idk",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class-idk",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Converting sf data frames to sp’s Spatial* class –> idk",
    "text": "Converting sf data frames to sp’s Spatial* class –> idk\n\n\nShow the code\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\n\n\nShow the code\nprint(mpsz)\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\n\nShow the code\nprint(childcare)\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\n\nShow the code\nprint(sg)\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Converting the Spatial* class into generic sp format",
    "text": "Converting the Spatial* class into generic sp format\n\n\nShow the code\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\n\n\nShow the code\nprint(childcare_sp)\n\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\nShow the code\nprint(sg_sp)\n\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format-1",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Converting the Spatial* class into generic sp format",
    "text": "Converting the Spatial* class into generic sp format\nThe code chunk below converts the Spatial* classes into generic sp objects:\n\n\nShow the code\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sg <- as(sg, \"SpatialPolygons\")\n\n\nNext, I will display the sp objects as shown below:\n\n\nShow the code\nchildcare_sp\n\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\nShow the code\nsg_sp\n\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nAnswer to challenge: > The class Spatial only holds metadata common to all derived classes (bounding box,coordinate reference system),and is convenient for defining methods that are common to all derived classes.\n– From here"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Converting the generic sp format into spatstat’s ppp format",
    "text": "Converting the generic sp format into spatstat’s ppp format\nAbout ppp format\nConversion:\n\n\nShow the code\nchildcare_ppp<- as(childcare_sp,\"ppp\")\nchildcare_ppp\n\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, I will plot childcare_ppp and examine the difference:\n\n\nShow the code\nplot(childcare_ppp)\n\n\n\n\n\nSummary statistics:\n\n\nShow the code\nsummary(childcare_ppp)\n\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Handling duplicated points",
    "text": "Handling duplicated points\nWe can check for duplication in a ppp object by using the code chunk below:\n\n\nShow the code\nany(duplicated(childcare_ppp))\n\n\n[1] TRUE\n\n\nTo count the number of co-incidence point, we will use the multiplicity() function as shown below (as there are too many entries, I have set eval to FALSE):\n\n\nShow the code\nmultiplicity(childcare_ppp)\n\n\nTo find out how many locations have more than 1 point,event, we can use the code chunk below:\n\n\nShow the code\nsum(multiplicity(childcare_ppp)>1)\n\n\n[1] 128\n\n\nThis shwos that there are 1128duplicated point events\nTo view the locations of these duplicate point events, we will plot childcare data by using the following code chunk:\n\n\nShow the code\ntmap_mode(\"view\")\ntm_shape(childcare) +\n  tm_dots(alpha=0.4,\n          size = 0.05)\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\nAnswer to challenge > The ones with multiplicity are the ones that are darker compared to others\nThere are three ways to solve the problem: - Delete the duplicates (however, you may lose some useful events) - jittering, which will add a small perturbation to the duplicate points so they do not occupy the exact same space. - Make each point “unique” and the attach the duplicates of the points to the patterns as marks, as attributes of the points.\nThe code chunk below shows the jittering approach (method 3)\n\n\nShow the code\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nNow, I will check if there remains any duplicated data\n\n\nShow the code\nany(duplicated(childcare_ppp_jit))\n\n\n[1] FALSE\n\n\nAlternatively,\n\n\nShow the code\nsum(multiplicity(childcare_ppp_jit)>1)\n\n\n[1] 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-own-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-own-owin-object",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Creating own owin object",
    "text": "Creating own owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\n\nShow the code\nsg_owin <- as(sg_sp, \"owin\")\n\n\nthe output object can be displayed using the plot() functions:\n\n\nShow the code\nplot(sg_owin)\n\n\n\n\n\nAnd here is the summary:\n\n\nShow the code\nsummary(sg_owin)\n\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Combining point events object and owin object",
    "text": "Combining point events object and owin object\nIn the last step of geospatial wrangling, we will extract childcare events that are located within Singapore\n\n\nShow the code\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nDIY\n\n\nShow the code\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\n\nComputing kernel density estimation using automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\n\nShow the code\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nThe below code chunk will display the derived kernel display.\n\n\nShow the code\nplot(kde_childcareSG_bw)\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\n\nShow the code\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n\n   sigma \n298.4095 \n\n\n\n\nRescaling KDE values\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\n\nShow the code\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nWe can re-run density() using the rescaled dataset and plot the output kde map.\n\n\nShow the code\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-automatic-badwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-automatic-badwidth-methods",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Working with different automatic badwidth methods",
    "text": "Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\n\nShow the code\nbw.CvL(childcareSG_ppp.km)\n\n\n   sigma \n4.543278 \n\n\n\n\nShow the code\nbw.scott(childcareSG_ppp.km)\n\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\n\nShow the code\nbw.ppl(childcareSG_ppp.km)\n\n\n    sigma \n0.3897114 \n\n\n\n\nShow the code\nbw.diggle(childcareSG_ppp.km)\n\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\n\nShow the code\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Working with different kernel methods",
    "text": "Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Computing KDE by using fixed bandwidth",
    "text": "Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\n\nShow the code\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Computing KDE by using adaptive bandwidth",
    "text": "Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\n\nShow the code\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\n\nShow the code\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-kde-output-into-grid-object.",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-kde-output-into-grid-object.",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Converting KDE output into grid object.",
    "text": "Converting KDE output into grid object.\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\n\nShow the code\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\nConverting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\n\nShow the code\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\n\nLet us take a look at the properties:\n\n\nShow the code\nkde_childcareSG_bw_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\nAssigning projections system\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster Raster Layer.\n\n\nShow the code\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Visualising the output in tmap",
    "text": "Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\n\nShow the code\ntm_shape(kde_childcareSG_bw_raster) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\", frame = FALSE))\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Comparing Spatial Point Patterns using KDE",
    "text": "Comparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\nExtracting study area\nThe code chunk below will be used to extract the target planning areas.\n\n\nShow the code\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\nPlotting target planning areas\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\nConverting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\n\nShow the code\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n\nCreating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\n\nShow the code\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n\nCombining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\n\nShow the code\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\n\nShow the code\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\nComputing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Testing spatial point patterns using Clark and Evans Test",
    "text": "Testing spatial point patterns using Clark and Evans Test\n\n\nShow the code\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\nConclusion: “We reject the null hypothesis”"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Clark and Evans Test: Choa Chu Kang planning area",
    "text": "Clark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\n\nShow the code\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.92098, p-value = 0.2377\nalternative hypothesis: two-sided\n\n\nConclusion: we do not reject null hypothesis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-tampines-planning-area",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Clark and Evans Test: Tampines planning area",
    "text": "Clark and Evans Test: Tampines planning area\n\n\nShow the code\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.80477, p-value = 0.000426\nalternative hypothesis: two-sided\n\n\nConclusion: We reject the null hypothesis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Choa Chu Kang planning area",
    "text": "Choa Chu Kang planning area\n\nComputing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\n\nShow the code\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\n\nShow the code\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\n\nShow the code\nplot(G_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Tampines planning area",
    "text": "Tampines planning area\n\nComputing G-function estimation\n\n\nShow the code\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\n\nShow the code\nG_tm.csr <- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\n\nShow the code\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area-1",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Choa Chu Kang planning area",
    "text": "Choa Chu Kang planning area\n\nComputing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\n\nShow the code\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\n\nShow the code\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\n\nShow the code\nplot(F_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area-1",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Tampines planning area",
    "text": "Tampines planning area\n\nComputing F-function estimation\nMonte Carlo test with F-function\n\n\nShow the code\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\n\nShow the code\nF_tm.csr <- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\n\nShow the code\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area-2",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Choa Chu Kang planning area",
    "text": "Choa Chu Kang planning area\n\nComputing K-function estimate\n\n\nShow the code\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\n\nShow the code\nK_ck.csr <- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\n\nShow the code\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area-2",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Tampines planning area",
    "text": "Tampines planning area\n\nComputing K-function estimation\n\n\nShow the code\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\n\nShow the code\nK_tm.csr <- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\n\nShow the code\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#choa-chu-kang-planning-area-3",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Choa Chu Kang planning area",
    "text": "Choa Chu Kang planning area\n\n\nShow the code\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\n\nShow the code\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\n\nShow the code\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#tampines-planning-area-3",
    "title": "Hands-on Exercise 3 and 4",
    "section": "Tampines planning area",
    "text": "Tampines planning area\n\nComputing L-function estimate\n\n\nShow the code\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\n\nShow the code\nL_tm.csr <- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\n\nShow the code\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In_class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In_class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Hello"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "In this exercise, we will be using the GrabPosisi data downloaded the previous week."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#folder-creation",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#folder-creation",
    "title": "In-class Exercise 2",
    "section": "Folder creation",
    "text": "Folder creation\nUsing the file navigation in RStudio, create a new subdirectory for the second in-class exercise."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#package-installation",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#package-installation",
    "title": "In-class Exercise 2",
    "section": "Package installation",
    "text": "Package installation\nThe following packages will be used and loaded in the R environment for this exercise:\n\narrow: handles databases and data conversions. Allows us to work with Parquet files, which are rare\nlubridate: helps lubricate data file\ntmap\ntidyverse\n\nCode chunk:\n\n\nShow the code\npacman::p_load(arrow, lubridate, tmap, tidyverse, sf)\n\n\n\n\n\n\n\n\nNote: saw callout notes on prof’s code, thought it looked cool. I can access it from the Visual tab but being able to write it in the source code seemed useful so I don’t have to constantly toggle between the two modes"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#importing-the-grab-posisi-dataset",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#importing-the-grab-posisi-dataset",
    "title": "In-class Exercise 2",
    "section": "Importing the Grab-Posisi Dataset",
    "text": "Importing the Grab-Posisi Dataset\n\n\n\n\n\n\nDanger\n\n\n\nWarning: Data is very, very large and will cause RStudio to crash if you upload it to Github. Remember to ensure .gitignore will ignore data/ subdirectories!"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#reading-the-grabposisi-data",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#reading-the-grabposisi-data",
    "title": "In-class Exercise 2",
    "section": "Reading the GrabPosisi data",
    "text": "Reading the GrabPosisi data\n\n\nShow the code\ndf <- read_parquet(file=\"../../data/data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#converting-the-pingtimestamp-to-date_time",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#converting-the-pingtimestamp-to-date_time",
    "title": "In-class Exercise 2",
    "section": "Converting the pingtimestamp to date_time",
    "text": "Converting the pingtimestamp to date_time\nThere was supposed to be a datetime stamp but it wasn’t in that format. As such, the data type needs to be changed\n\n\nShow the code\ndf$pingtimestamp <- as_datetime(df$pingtimestamp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#writing",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#writing",
    "title": "In-class Exercise 2",
    "section": "Writing",
    "text": "Writing\nNow, we will write it to a separate rds file:\n\n\nShow the code\nwrite_rds(origin_df, \"data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"data/rds/destination_df.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#reading",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#reading",
    "title": "In-class Exercise 2",
    "section": "Reading",
    "text": "Reading\n\n\nShow the code\norigin_df <- read_rds(\"data/rds/origin_df.rds\")\ndestination_df <- read_rds(\"data/rds/destination_df.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#visualising-the-frequency-distribution",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#visualising-the-frequency-distribution",
    "title": "In-class Exercise 2",
    "section": "Visualising the Frequency Distribution",
    "text": "Visualising the Frequency Distribution\nNext, I will be showing the distribution of origin trips by the day of the week.\n\n\nShow the code\nggplot(data=origin_df, \n       aes(x=weekday)) + \n  geom_bar()\n\n\n\n\n\nAs can be seen, the number of trips daily seem to be fairly equally distributed throughout the week."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#visualising-as-point-symbol-map",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#visualising-as-point-symbol-map",
    "title": "In-class Exercise 2",
    "section": "Visualising as Point Symbol Map",
    "text": "Visualising as Point Symbol Map\nWe also want to visualise the geospatial distribution of origin points.\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(origin_sf) +\n  tm_dots()\n\n\n\n\n\nWhile the above does show the distribution of the origin points, they are not contextualised according to the landscape of Singapore."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#diy",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#diy",
    "title": "In-class Exercise 2",
    "section": "DIY",
    "text": "DIY\n\n\nShow the code\nmpsz2019 <- st_read(\"data/geospatial/MPSZ2019.kml\") %>%\n  st_transform(crs=3414)\n\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `D:\\KrisLBT\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\geospatial\\MPSZ2019.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nNext, I will be trying to merge the dots with the base layer."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#diy-2",
    "href": "In-class_Ex/In-class_Ex02/In_class_Ex02.html#diy-2",
    "title": "In-class Exercise 2",
    "section": "DIY 2",
    "text": "DIY 2\n\n\nShow the code\ntm_shape(mpsz2019) +\n  tm_polygons() +\ntm_shape(origin_sf) +\n  tm_dots()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In_class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In_class_Ex03.html",
    "title": "In-class exercise 3",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\nmaptools\nsf\nspatstat\ntmap\ntidyverse\n\n\n\nShow the code\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse)\n\n\nAs there may be issues with installing maptools, you may use the following:\n\n\nShow the code\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\nAfter that, you can rerun the first code block."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#deriving-coastaloutline",
    "href": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#deriving-coastaloutline",
    "title": "In-class exercise 3",
    "section": "Deriving CoastalOutline",
    "text": "Deriving CoastalOutline\nFirst, we can plot the Master Plan Subzone Boundary 2014\n\n\nShow the code\nplot(mpsz_sf)\n\n\n\n\n\nThen we can blend away the boundaries.\n\n\nShow the code\nsg_sf <- mpsz_sf %>%\n  st_union()\n\n\n\n\nShow the code\nplot(sg_sf)\n\n\n\n\n\nWe use st_union() over st_combine() as st_union() will treat the output as a singular polygon while st_combine() will treat the individual subzones as their own polygon.\nWith that, we have made the CoastalOutline"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#creating-ppp-objects-sf-method",
    "href": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#creating-ppp-objects-sf-method",
    "title": "In-class exercise 3",
    "section": "Creating ppp objects: sf method",
    "text": "Creating ppp objects: sf method\nWe can use the more efficient as.ppp() method to convert to ppp.\n\n\nShow the code\nchildcare_ppp <- as.ppp(childcare_sf)\n\n\n\n\nShow the code\nsummary(childcare_ppp)\n\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "This is the course website for IS415 in AY2022/2023 Semester 2 and is where you can find my course work done for this module."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html",
    "title": "Take Home Exercise 01: Part 1",
    "section": "",
    "text": "It is important for local and government urban planners to know and understand how, where and when people move. For Singapore, data regarding human mobility has largely been collected and disseminated by the Land Transport Authority (LTA). However, they have only collected and publicised data regarding passenger volume from trains stations and bus stops. While immensely helpful, it still leaves out crucial information about human mobility through other means of transport, making it incomphrensive.\nIn 2020, Grab released Grab Posisi, a data set regarding the origin and destinations of Grab taxi users in Singapore.\nIn this take-home exercise, I will be finding the geographical and spatio-temporal distribution of Grab hailing service locations in Singapore.\nThe distribution will be analysed using the following, which will be displayed on the openstreetmap of Singapore:\n\nTraditional Kernel Density Estimation (KDE) layers: to analyse the where origin points tend to cluster\nNetwork Kernel Density Estimation (NKDE): to analyse the clusters of origin points, as constrained by the road."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#network-constrained-kde-netkde-analysis",
    "href": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#network-constrained-kde-netkde-analysis",
    "title": "In-class exercise 3",
    "section": "Network Constrained KDE (NetKDE) Analysis",
    "text": "Network Constrained KDE (NetKDE) Analysis\n\nPreparing the lixels objects\n\n\nShow the code\nlixels <- lixelize_lines(network, \n                         750, \n                         mindist = 375)\n                         #mindist should be half of the first value"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#generating-line-points",
    "href": "In-class_Ex/In-class_Ex03/In_class_Ex03.html#generating-line-points",
    "title": "In-class exercise 3",
    "section": "Generating line points",
    "text": "Generating line points\n\n\nShow the code\nsamples <- lines_center(lixels)\n\n\n\nPerforming NetKDE\nCompute the NetKDE.\n\n\nShow the code\ndensities <- nkde(network, \n                  events = childcare,\n                  w = rep(1,nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\n\nWhat can we learn from the code chunk above?\n\nkernel_name argument indicates that quartic kernel is used. Are possible kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform. method argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nmethod=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\nmethod=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\nmethod=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\nThe user guide of spNetwork package provide a comprehensive discussion of nkde(). You should read them at least once to have a basic understanding of the various parameters that can be used to calibrate the NetKDE model.\n\n\nCreate density\n\n\nShow the code\nsamples$density <- densities\nlixels$density <- densities\n\n\nSince the values are very small, rescale them:\n\n\nShow the code\n# rescaling to help the mapping\nsamples$density <- samples$density*1000\nlixels$density <- lixels$density*1000\n\n\nGenerate the map\n\n\nShow the code\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nNetwork Constrained G- and K-Function Analysis\nIn this section, we are going to perform complete spatial randomness (CSR) test by using kfunctions() of spNetwork package. The null hypothesis is defined as:\nHo: The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf this hypothesis is rejected, we may infer that the distribution of childcare centres are spatially interacting and dependent on each other; as a result, they may form nonrandom patterns.\n\n\nShow the code\nkfun_childcare <- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\n\nWhat can we learn from the code chunk above?\nThere are ten arguments used in the code chunk above they are:\n\nlines: A SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame (may crash if some geometries are invalid).\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network. start: A double, the start value for evaluating the k and g functions.\nend: A double, the last value for evaluating the k and g functions.\nstep: A double, the jump between two evaluations of the k and g function.\nwidth: The width of each donut for the g-function.\nnsim: An integer indicating the number of Monte Carlo simulations required. In the above example, 50 simulation was performed. Note: most of the time, more simulations are required for inference\nresolution: When simulating random points on the network, selecting a resolution will reduce greatly the calculation time. When resolution is null the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points are selected vertices on the new network.\nconf_int: A double indicating the width confidence interval (default = 0.05).\n\nFor the usage of other arguments, you should refer to the user guide of spNetwork package.\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nFor example, we can visualise the ggplot2 object of k-function by using the code chunk below.\n\n\nShow the code\nkfun_childcare$plotk\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol planning area. The gray envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%. Because the blue line between the distance of 250m-400m are below the gray area, we can infer that the childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#extraction-of-the-coastal-outline-of-mainland-singapore",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#extraction-of-the-coastal-outline-of-mainland-singapore",
    "title": "Take Home Exercise 01: Part 1",
    "section": "Extraction of the Coastal Outline of Mainland Singapore",
    "text": "Extraction of the Coastal Outline of Mainland Singapore\nFor the purposes of this analysis, we will also need to extract the Coastal Outline of Singapore. This is to create a boundary for all the points to fall under.\nFirst, we need to read Singapore Master Plan Subzone 2014 to get Singapore’s shape overall.\n\n\nShow the code\nmpsz_sf <- st_read(dsn = \"../../data/data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\KrisLBT\\IS415-GAA\\data\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe have to check the CRS to ensure that it is in the correct coordinates system.\n\n\nShow the code\nst_crs(mpsz_sf)\n\n\nSince it is in the wrong CRS (WGS84), we have to correct it to SVY21.\n\n\nShow the code\nmpsz_sf <- st_transform(mpsz_sf, 3414)\n\n\nNow, we can plot the island.\n\n\nShow the code\nplot(mpsz_sf)\n\n\nWe notice that the planning subzone includes areas where Grab does not serve due to lack of bridges. Hence, any roads in unavailable areas would either not be useful or actually distort the network analysis.\nMost of the areas unserved by Grab are the outer islands. For this, we can identify which of the outer islands to exclude from our analysis.\n\n\nShow the code\nouter_islands<-  filter(mpsz_sf, grepl('ISLAND', PLN_AREA_N))\nplot(outer_islands[\"SUBZONE_N\"])\n\n\nHowever, we realise that not all the islands are unavailable to Grab drivers. Grab drivers are able to pick up and drop off at Sentosa.\nSince 2019, Grab drivers have been allowed entry to Jurong Island, provided they have a security pass. However, given that very few drivers are allowed entry and the fact that this region is generally inaccessible to the public, we will be excluding them.\nHence, the islands we need to exclude are:\n\nSemakau\nSouthern Group\nSudong\nNorth-eastern Islands\nJurong Island and Bukom\n\n\n\nShow the code\nserviced_area <- mpsz_sf %>%\n  filter(!grepl(\"SEMAKAU|SOUTHERN GROUP|SUDONG|NORTH-EASTERN ISLANDS|JURONG ISLAND AND BUKOM\", SUBZONE_N)) \nplot(serviced_area)\n\n\nNow, we can blend away the boundaries.\n\n\nShow the code\nsg_sf <- serviced_area %>%\n  st_union()\n\n\nPlot the sg_sf and we now see we have the CoastalOutline of Singapore that is served by Grab.\n\n\nShow the code\nplot(sg_sf)\n\n\nWe can save it as the CoastalOutline as a shapefile and read it again\n\n\nShow the code\n# writing the CoastalOutline\nst_write(sg_sf, 'data/CoastalOutline.shp')\n\n\n\n\nShow the code\n# reading the CoastalOutline\nsg_sf <- st_read(dsn='data/',\n                 layer = \"CoastalOutline\")\n\n\nReading layer `CoastalOutline' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21494.3 xmax: 55941.94 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#handling-of-the-grab-posisi-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#handling-of-the-grab-posisi-data",
    "title": "Take Home Exercise 01: Part 1",
    "section": "Handling of the Grab Posisi data",
    "text": "Handling of the Grab Posisi data\nWe will also have to handle the Grab Posisi data.\nThe data is quite large. As such, Grab has divided into 10 parquet files for easier distribution.\n\nReading the Grab Posisi Data\nI will now be loading the Grab Posisi data\n\n\nShow the code\ndf <- read_parquet(file=\"../../data/data/GrabPosisi/part-00000.snappy.parquet\")\ndf1 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00001.snappy.parquet\")\ndf2 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00002.snappy.parquet\")\ndf3 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00003.snappy.parquet\")\ndf4 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00004.snappy.parquet\")\ndf5 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00005.snappy.parquet\")\ndf6 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00006.snappy.parquet\")\ndf7 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00007.snappy.parquet\")\ndf8 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00008.snappy.parquet\")\ndf9 <- read_parquet(file=\"../../data/data/GrabPosisi/part-00009.snappy.parquet\")\n\n\n\n\nHandling the Grab Posisi data\n\nTime stamp\nUpon investigating the file, I noticed that there was supposed to be a datetime stamp but it wasn’t in that format. As such, the data type needs to be changed.\n\n\nShow the code\ndf$pingtimestamp <- as_datetime(df$pingtimestamp)\ndf1$pingtimestamp <- as_datetime(df1$pingtimestamp)\ndf2$pingtimestamp <- as_datetime(df2$pingtimestamp)\ndf3$pingtimestamp <- as_datetime(df3$pingtimestamp)\ndf4$pingtimestamp <- as_datetime(df4$pingtimestamp)\ndf5$pingtimestamp <- as_datetime(df5$pingtimestamp)\ndf6$pingtimestamp <- as_datetime(df6$pingtimestamp)\ndf7$pingtimestamp <- as_datetime(df7$pingtimestamp)\ndf8$pingtimestamp <- as_datetime(df8$pingtimestamp)\ndf9$pingtimestamp <- as_datetime(df9$pingtimestamp)\n\n\n\n\nMerging them into 1 data frame\nI also noticed that the the same ride might actually have origin and destination points through multiple data frames. As such, we need to merge them before we can extract the origin points.\n\n\nShow the code\norigin_df_all <- df %>%\n  rbind(df1) %>%\n  rbind(df2) %>%\n  rbind(df3) %>%\n  rbind(df4) %>%\n  rbind(df5) %>%\n  rbind(df6) %>%\n  rbind(df7) %>%\n  rbind(df8) %>%\n  rbind(df9)\n\n\n\n\nExtraction of Origin\nNow, I will be extracting the origin.\nThe way I did it below is by performing the following steps\n\narrange it according to the trj_id (unique id determining where the person wants to at that point)\narranging it according to the time stamp (beginning and end)\ngetting the first row - mutating the data to weekday, start hour and the day\n\n\n\nShow the code\norigin_df <- origin_df_all %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr= factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\nWriting of Origin Data to RDS\nNow, I will write the origin data to rds for easier future handling.\n\n\nShow the code\nwrite_rds(origin_df, \"data/rds/origin_dfs.rds\")\n\n\n\n\nReading of RDS data\nNow, we can clear the data in our environment and just read the rds data we saved.\n\n\nShow the code\norigin_df <- read_rds(\"data/rds/origin_dfs.rds\")"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#analysis-of-origins",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#analysis-of-origins",
    "title": "Take Home Exercise 01",
    "section": "Analysis of Origins",
    "text": "Analysis of Origins\n\nVisualising the Frequency Distribution\n\n\nShow the code\nggplot(data=origin_df,\n       aes(x=weekday)) +\n  geom_bar()\n\n\n\n\n\nAs can be seen, the number of trips daily seem to be fairly equally distributed throughout the week.\n\n\nVisualising the Origins as a Point Map Symbol\nWe can visualise the geospatial distribution of the origin points.\n\n\nShow the code\norigins_sf <- st_as_sf(origin_df, coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs=3414)\n\n\nNow, we can visualise it using the code chunk below:\n\n\nShow the code\ntm_shape(mpsz_sf)+\n  tm_polygons()+\ntm_shape(origins_sf) +\n  tm_dots()\n\n\n\n\nConvert sf data frames to sp’s Spatial class\nWe can convert these data to sp’s Spatial* class and then convert into a generic sp format.\n\n\nShow the code\nsg <- as_Spatial(sg_sf)\nmpsz <- as_Spatial(mpsz_sf)\norigins <- as_Spatial(origins_sf) \n\n\nAnd into SpatialPolygon format\n\n\nShow the code\nsg_sp <- as(sg, \"SpatialPolygons\")\norigins_sp <- as(origins, \"SpatialPoints\")\n\n\nWe then convert it to ppp format.\n\n\nShow the code\norigins_ppp <- as(origins_sp, \"ppp\")\norigins_ppp\n\n\nPlanar point pattern: 28000 points\nwindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n\n\nNow, I will plot origins_ppp.\n\n\nShow the code\nplot(origins_ppp)\n\n\nWe must check for duplicates in the data using the code chunk below:\n\n\nShow the code\nany(duplicated(origins_ppp))\n\n\n[1] FALSE\n\n\nAs there are no duplicates within the data, we do not have to apply any more transformation to the data.\n\n\nCreate owin data\nNow, we can convert the Coastal Outline to owin data and plot it out.\n\n\nShow the code\nsg_owin <- as(sg_sp, \"owin\")\nplot(sg_owin)\n\n\n\n\n\n\n\nCombining events\nWe will now extract Grab origins within the Singapore CoastalOutline\n\n\nShow the code\norigins_SG_ppp = origins_ppp[sg_owin]\n\n\n\n\nShow the code\nplot(origins_SG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, I have learned how to compute spatial weights using R, which entail the following:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package.\n\n\n\n\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer: This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\nFirstly, I will ensure that spdep, sf, tmap and tidyverse are installed in R and load it into my environment.\n\n\nShow the code\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\n\nNow, I will be loading the data into my R environment.\n\n\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be a simple feature Object of sf.\n\n\nShow the code\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nWe will be using the read_csv() function of the readr package. The output will be an R data.frame class\n\n\nShow the code\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nThe code chunk below will be used to join the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\n\nShow the code\n#combines both the hunan and hunan2012 data.frames together\n#subsequently selects certain (2-5, 8 and 16th) columns only\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\n\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\n\nShow the code\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThis section will deal with the usage of poly2nb()of the spdep package. It is used to compute contiguity weight matrices for a given study area. It does this by building a neighbours list based on regions with contiguous boundaries.\nThe documentation shows a “queen” argument, which takes in a boolean value (TRUE or FALSE) and has been set to TRUE as default.\n\n\nThe code chunk below is used to compute the Queen contiguity weight matrix .\n\n\nShow the code\n#this code will compute the Queen contiguity weight matrix\nwm_q <- poly2nb(hunan, queen=TRUE)\n#this one provides the summary report of the Queen contiguity weight matrix\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows the following\n\nThere are 88 area regions in Hunan\nThe most connected area unit has 11 neighbours\nThere are two area units with only one link\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\n\nShow the code\nwm_q[[1]]\n\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbours. The numbers afterwards show the area region numbers of the neighbours.\nWe can retrieve the county name of area region (Anxiang) using the following code chunk:\n\n\nShow the code\nhunan$County[1]\n\n\n[1] \"Anxiang\"\n\n\nTo reveal the names of its neighbours, type the following:\n\n\nShow the code\nhunan$NAME_3[c(2,3,4,57,85)]\n\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these counties using the following:\n\n\nShow the code\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\n\nShow the code\nstr(wm_q)\n\n\n\n\n\n\n\n\nWarning: This might span a few pages. Don’t print this one out\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to compute the Rook contiguity weight matrix.\n\n\nShow the code\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows the same results as the above summary report except that the maximum number of links is 10, instead of 11.\n\n\n\nA connectivity graph displays a line connecting points to each neighbouring point. However, we are working with polygon data, not point data. The most common way to resolve this is by using polygon centroids. We will calculate them using the sf package before creating the graphs.\n\n\nWe will need to generate points corresponding to each polygon before we can make our connectivity graph. However, running st_centroid() won’t work in this specific context; we need the coordinates in separate dataframes for this to work. To do this, we need to use a mapping function. This will allow us to apply a given function to to each element of a vector and return a vector of the same length. Our input geometry will be the geometry column of hunan. We will be using the map_dbl() mapping function from the purrr package.\nTo get the longitude and latitude of each centroid, map the st_centroid() function over each row in hunan and access the different coordinates using double bracket notation and the appropriate number. After getting the aforementioned values, we can merge the data.frames together\n\n\nShow the code\n# get the longitude (value = 1)\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n#get the latitude (value = 2)\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n#merge the two data.frames\ncoords <- cbind(longitude, latitude)\n\n#check the the first few values to ensure that they are correctly formatted\nhead(coords)\n\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n\n\n\n\nShow the code\n#plotting the Queen contiguity based neighbour map\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\nShow the code\n#plotting the Rook contiguity based neighbour map\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nShow the code\n#Map BOTH the Queen and Rook based Contiguity based maps\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nI will be computing the distance-based neighbours using the dnearneigh()of the spdep package.\nThe dnearneigh() function identifies neighbours of region points by Euclidean distance with a distance band of lower d1= and upper d2= bounds, using the bounds= argument. If unpojected coordinates are used and either specified in the coordinates object x or with object x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated using WGS84 reference ellipsoid.\n\n\nFirst, we need to determine the upper limit for the distance band\n\nUse the knearneigh() function of spdep to return a matrix with the indices of the points belowing to the set of the k nearest neighbours\nConvert the knn object returned by the previous function into a neighbour’s list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb()\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns the units of the coordinates if the coordinates are projected, in km otherwise\nRemove the list structure of the returned object by using unlist()\n\n\n\nShow the code\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\n#generate the summary report\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79km, which can be used as the upper bound to provide certainty that all units have at least 1 neighbour.\n\n\n\nNow, we will compute the disstance weight matrix by using dnearneigh() as shown below:\n\n\nShow the code\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, we can use str() to display the content of wm_d62 weight matrix.\n\n\nShow the code\nstr(wm_d62)\n\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nShow the code\nn_comp <- n.comp.nb(wm_d62)\nn_comp$nc\n\n\n[1] 1\n\n\n\n\nShow the code\ntable(n_comp$comp.id)\n\n\n\n 1 \n88 \n\n\n\n\nNext, we will plot the distance weight matrix:\n\n\nShow the code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\nThe red lines show the 1st nearest neighbours and the black lines shows the links of the neighbours within a cut-off distance of 62km.\nAlternatively, we can plot these two side by side:\n\n\nShow the code\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed weight distance weight matrix is that denser areas have more neighbours while less dense areas have fewer neighbours. Having many neighbours smoothens the neighbour relationships across more neighbours.\nIt is possible to control this directly using k-nearest neighbours, either accepting assymetric neighbours or imposing symemetry as shown in the code chunk below:\n\n\nShow the code\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nDisplay the content:\n\n\nShow the code\nstr(knn6)\n\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNow, each county has exactly 6 neighbours.\n\n\n\n\nIn this section, I will be deriving a spatial weight matrix based on Inversed Distance method.\nFirst, I will compute the distances between the areas using the nbdists() of spdep.\n\n\nShow the code\ndist <- nbdists(wm_q, coords, longlat = TRUE)\nids <- lapply(dist, function(x) 1/(x))\nids\n\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\nNext, we need to assign weights to each neighbouring polygon. In our case, each neighbouring polygon will be assigned equal weight (style=“W”). This will be done by assigning the inverse of the number of neighbours (i.e. 1/(# of neighbours). While this is intuitive, it has the major drawback that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\nShow the code\nrswm_q <- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\n\nShow the code\nrswm_q$weights[10]\n\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\n\nShow the code\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\n\nShow the code\nrswm_ids$weights[1]\n\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n\nShow the code\nsummary(unlist(rswm_ids$weights))\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n\n\n\n\nIn this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\n\nShow the code\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWe will retrieve the GDPPC of the 5 counties by using the code chunk below:\n\n\nShow the code\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\n\nShow the code\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\n\nShow the code\nhead(hunan)\n\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\n\nShow the code\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\n\nShow the code\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nFirst, let us examine the result by using the code chunk below.\n\n\nShow the code\nlag_sum\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\n\nShow the code\nhunan <- left_join(hunan, lag.res)\n\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\n\nShow the code\nwm_qs <- include.self(wm_q)\n\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\n\nShow the code\nwm_qs[[1]]\n\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw().\n\n\nShow the code\nwm_qs <- nb2listw(wm_qs)\nwm_qs\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\n\nShow the code\nlag_w_avg_gpdpc <- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\n\nShow the code\nlag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res <- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\n\nShow the code\nhunan <- left_join(hunan, lag_wm_qs.res)\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\n\nShow the code\nhunan %>%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\n\nShow the code\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions.\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\n\nShow the code\nwm_qs <- include.self(wm_q)\nwm_qs\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\n\nShow the code\nb_weights <- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\n\nShow the code\nb_weights2 <- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\n\nShow the code\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\n\nShow the code\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\n\nShow the code\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\n\nShow the code\nhunan %>%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\n\nShow the code\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#data-handling",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#data-handling",
    "title": "Take Home Exercise 01",
    "section": "Data Handling",
    "text": "Data Handling\n\nHandling of Road Data\nNow, we can read the road data as provided by openstreetmap. Note that it provides data for Malaysia, Singapore and Brunei all at once.\n\n\nShow the code\nall_roads <- st_read(dsn='../../data/data/data',\n                     layer = 'gis_osm_roads_free_1')\n\n\nWe realise that it is in WGS 84, not in SVY21 so we have to transform the data.\n\n\nShow the code\nall_roads <- st_transform(all_roads, 3414)\n\n\nWe can check the CRS again for all_roads.\n\n\nShow the code\nst_crs(all_roads)\n\n\nSince we’re only interested in the roads in mainland Singapore, we have to filter the roads.\n\n\nShow the code\n# get all roads in mainland Singapore\nSG_roads <- st_intersection(all_roads, sg_sf)\n\n# write out the roads into a separate .shp file for easier future handling\nst_write(SG_roads, 'data/SG_roads.shp')\n\n\nWe can now read it from here.\n\n\nShow the code\nSG_roads <- st_read(dsn='data', layer= 'SG_roads')\n\n\nReading layer `SG_roads' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 227969 features and 10 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 2679.373 ymin: 23099.51 xmax: 50957.8 ymax: 50220.06\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\nGetting the Roads within the Subzones\nNow, we can find the streets that exist only inside the subzones.\n\n\nShow the code\n# get roads only in the aforementioned subzones\nCA_roads <- st_intersection(SG_roads, CA)\nWL_roads <- st_intersection(SG_roads, WL)\nJE_roads <- st_intersection(SG_roads, JE)\nMP_roads <- st_intersection(SG_roads, MP)\n\n\n\n\nShow the code\nCA_roads\n\n\nSimple feature collection with 4007 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 42577.65 ymin: 32548.05 xmax: 50286.8 ymax: 41649.2\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code      fclass                  name  ref oneway maxspeed layer\n356  22617051 5113     primary         Loyang Avenue <NA>      F       70     0\n360  22617159 5113     primary         Loyang Avenue <NA>      F       70     0\n1348 22981700 5113     primary       Telok Paku Road <NA>      F       50     0\n3201 34403286 5114   secondary            Loyang Way <NA>      F       50     0\n3207 34403387 5122 residential Changi North Street 1 <NA>      B        0     0\n3208 34403405 5122 residential Changi North Crescent <NA>      B       50     0\n3209 34403417 5122 residential     Changi North Rise <NA>      B        0     0\n4001 42063713 5141     service                  <NA> <NA>      F        0     0\n4002 42063715 5141     service                  <NA> <NA>      B        0     0\n4003 42063716 5141     service                  <NA> <NA>      B        0     0\n     bridge tunnel OBJECTID SUBZONE_NO   SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N\n356       F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n360       F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n1348      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3201      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3207      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3208      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3209      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n4001      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n4002      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n4003      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n     PLN_AREA_C    REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n356          CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n360          CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n1348         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3201         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3207         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3208         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3209         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n4001         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n4002         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n4003         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n       Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n356  38928.66   14918.11    4848517 LINESTRING (44617.88 41088....\n360  38928.66   14918.11    4848517 LINESTRING (43851.2 39632.9...\n1348 38928.66   14918.11    4848517 LINESTRING (45352.67 41113....\n3201 38928.66   14918.11    4848517 LINESTRING (43761.28 39560....\n3207 38928.66   14918.11    4848517 LINESTRING (43152.23 36906....\n3208 38928.66   14918.11    4848517 LINESTRING (42843.89 36842....\n3209 38928.66   14918.11    4848517 LINESTRING (43130.89 36812....\n4001 38928.66   14918.11    4848517 LINESTRING (43433.23 37663....\n4002 38928.66   14918.11    4848517 LINESTRING (43436.11 37657....\n4003 38928.66   14918.11    4848517 LINESTRING (43511.5 37906.7...\n\n\nShow the code\nWL_roads\n\n\nSimple feature collection with 7165 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 20613.4 ymin: 44814.83 xmax: 25593.19 ymax: 49200.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code        fclass                name  ref oneway maxspeed layer\n796  22773625 5115      tertiary  Woodlands Avenue 6 <NA>      F       40     0\n819  22774351 5131 motorway_link                <NA> <NA>      F       50     0\n825  22774532 5122   residential  Woodlands Drive 14 <NA>      F       40     0\n826  22774537 5122   residential  Woodlands Drive 53 <NA>      B       50     0\n827  22774541 5122   residential  Woodlands Drive 43 <NA>      F       40     0\n832  22775173 5115      tertiary  Woodlands Avenue 5 <NA>      F       60     0\n834  22775385 5113       primary Woodlands Avenue 12 <NA>      F       70     0\n835  22775386 5114     secondary  Woodlands Avenue 1 <NA>      F       50     0\n836  22775389 5114     secondary  Woodlands Avenue 1 <NA>      F       50     0\n3703 37584630 5111      motorway  Seletar Expressway  SLE      F       90     1\n     bridge tunnel OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND\n796       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n819       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n825       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n826       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n827       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n832       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n834       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n835       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n836       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n3703      T      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n     PLN_AREA_N PLN_AREA_C     REGION_N REGION_C          INC_CRC FMEL_UPD_D\n796   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n819   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n825   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n826   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n827   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n832   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n834   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n835   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n836   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n3703  WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n       X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n796  23609.57 45692.88   5211.384    1576001 LINESTRING (24007.3 45538.1...\n819  23609.57 45692.88   5211.384    1576001 LINESTRING (22821.47 45515....\n825  23609.57 45692.88   5211.384    1576001 LINESTRING (23444.28 46022....\n826  23609.57 45692.88   5211.384    1576001 LINESTRING (23990.45 46088....\n827  23609.57 45692.88   5211.384    1576001 LINESTRING (23447.47 46014....\n832  23609.57 45692.88   5211.384    1576001 LINESTRING (24645.58 46021....\n834  23609.57 45692.88   5211.384    1576001 LINESTRING (23836.85 45038....\n835  23609.57 45692.88   5211.384    1576001 LINESTRING (23124.88 45989....\n836  23609.57 45692.88   5211.384    1576001 LINESTRING (24156.4 45407.0...\n3703 23609.57 45692.88   5211.384    1576001 LINESTRING (23684.88 44959....\n\n\nShow the code\nJE_roads\n\n\nSimple feature collection with 7131 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 14254.68 ymin: 30994.22 xmax: 19398.25 ymax: 37289.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code       fclass                     name  ref oneway maxspeed\n1084 22903885 5114    secondary             Penjuru Road <NA>      F       60\n1085 22903886 5121 unclassified             Penjuru Road <NA>      F       60\n1443 23101520 5112        trunk              Jalan Buroh <NA>      F       70\n3791 39959160 5112        trunk              Jalan Buroh <NA>      F       70\n3792 39959161 5112        trunk              Jalan Buroh <NA>      F       70\n5003 70583774 5115     tertiary              Pandan Road <NA>      B       50\n5004 70583780 5121 unclassified             Penjuru Lane <NA>      B       50\n5005 70583783 5114    secondary          Tanjong Penjuru <NA>      B       50\n5006 70583786 5114    secondary          Tanjong Penjuru <NA>      F       50\n5007 70583790 5121 unclassified Tanjong Penjuru Crescent <NA>      B       50\n     layer bridge tunnel OBJECTID SUBZONE_NO        SUBZONE_N SUBZONE_C CA_IND\n1084     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n1085     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n1443     1      T      F       80         10 PENJURU CRESCENT    JESZ10      N\n3791     1      T      F       80         10 PENJURU CRESCENT    JESZ10      N\n3792     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5003     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5004     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5005     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5006     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5007     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n      PLN_AREA_N PLN_AREA_C    REGION_N REGION_C          INC_CRC FMEL_UPD_D\n1084 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n1085 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n1443 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n3791 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n3792 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5003 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5004 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5005 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5006 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5007 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n       X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1084 17651.31 31799.61   9876.049    3049720 LINESTRING (16991.44 32621....\n1085 17651.31 31799.61   9876.049    3049720 LINESTRING (16738.48 31589....\n1443 17651.31 31799.61   9876.049    3049720 LINESTRING (16290.72 32753....\n3791 17651.31 31799.61   9876.049    3049720 LINESTRING (19056.98 32186....\n3792 17651.31 31799.61   9876.049    3049720 LINESTRING (18978.73 32113....\n5003 17651.31 31799.61   9876.049    3049720 LINESTRING (18411.82 31559....\n5004 17651.31 31799.61   9876.049    3049720 LINESTRING (17208.01 32320....\n5005 17651.31 31799.61   9876.049    3049720 LINESTRING (16869.64 32131....\n5006 17651.31 31799.61   9876.049    3049720 LINESTRING (17506.95 32049....\n5007 17651.31 31799.61   9876.049    3049720 LINESTRING (17697.91 31764....\n\n\nShow the code\nMP_roads\n\n\nSimple feature collection with 2864 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 32697.12 ymin: 29763 xmax: 37589.95 ymax: 32843.37\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code       fclass                         name  ref oneway\n922  22810641 5114    secondary    Tanjong Katong Road South <NA>      F\n1202 22930502 5113      primary            Marina East Drive <NA>      F\n3760 39477475 5111     motorway           East Coast Parkway  ECP      F\n3761 39477476 5111     motorway           East Coast Parkway  ECP      F\n4078 44122367 5152     cycleway               Park Connector <NA>      B\n4097 44133236 5153      footway      Underpass to Meyer Road <NA>      B\n4140 44488255 5153      footway                  Katong Park <NA>      B\n4141 44488257 5121 unclassified East Coast Park Service Road <NA>      B\n4142 44488265 5114    secondary    Tanjong Katong Road South <NA>      F\n5509 74729034 5111     motorway           East Coast Parkway  ECP      F\n     maxspeed layer bridge tunnel OBJECTID SUBZONE_NO        SUBZONE_N\n922        50     0      F      F       44          5 MARINA EAST (MP)\n1202       60     0      F      F       44          5 MARINA EAST (MP)\n3760       90     1      T      F       44          5 MARINA EAST (MP)\n3761       80     0      F      F       44          5 MARINA EAST (MP)\n4078        0     0      F      F       44          5 MARINA EAST (MP)\n4097        0    -1      F      T       44          5 MARINA EAST (MP)\n4140        0    -1      F      T       44          5 MARINA EAST (MP)\n4141       50     0      F      F       44          5 MARINA EAST (MP)\n4142       50     1      T      F       44          5 MARINA EAST (MP)\n5509       90     0      F      F       44          5 MARINA EAST (MP)\n     SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C       REGION_N REGION_C\n922     MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n1202    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n3760    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n3761    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4078    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4097    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4140    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4141    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4142    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n5509    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n              INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area\n922  1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n1202 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n3760 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n3761 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4078 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4097 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4140 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4141 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4142 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n5509 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n                           geometry\n922  LINESTRING (35230.6 31057.3...\n1202 LINESTRING (33760.43 30638....\n3760 LINESTRING (33860.36 30899....\n3761 LINESTRING (33706.71 30894....\n4078 LINESTRING (34789.2 30864.6...\n4097 LINESTRING (34772.07 30914....\n4140 LINESTRING (34005.49 30906....\n4141 LINESTRING (35255.73 30985,...\n4142 LINESTRING (35227.24 31091....\n5509 LINESTRING (34854.12 30932....\n\n\nWe notice that all of the above are geometry type geometry and not a linestring. We can convert them with the following code chunk:\n\n\nShow the code\nCA_roads <- CA_roads %>%\n  st_cast(\"LINESTRING\")\n\nWL_roads <- WL_roads %>%\n  st_cast(\"LINESTRING\")\n\nJE_roads <- JE_roads %>%\n  st_cast(\"LINESTRING\")\n\nMP_roads <- MP_roads %>%\n  st_cast(\"LINESTRING\")\n\n\n\n\nExtraction of the Events Within the Subzones\nBefore we can conduct analysis on the network, we will also need to constrict the events to exclusively the ones that occurred within these two subzones.\n\n\nShow the code\n#extraction of origin events that occurred within Changi and Marine Parade\nCA_origins <- st_intersection(origins_sf, CA)\nWL_origins <- st_intersection(origins_sf, WL)\nJE_origins <- st_intersection(origins_sf, JE)\nMP_origins <- st_intersection(origins_sf, MP)\n\n\nWe can now plot this data. In this instance, we can use Changi as an example:\n\n\nShow the code\ntmap_mode('view')\ntm_shape(CA_origins)+\n  tm_dots() +\n  tm_shape(CA_roads) +\n  tm_lines()\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#network-constrained-kde-netkde-analysis",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#network-constrained-kde-netkde-analysis",
    "title": "Take Home Exercise 01",
    "section": "Network Constrained KDE (NetKDE) Analysis",
    "text": "Network Constrained KDE (NetKDE) Analysis\n\nPreparing the lixel objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\n\nShow the code\nCA_lixels <- lixelize_lines(CA_roads, \n                         750, \n                         mindist = 375)\nWL_lixels <- lixelize_lines(WL_roads, \n                         750, \n                         mindist = 375)\nJE_lixels <- lixelize_lines(JE_roads, \n                         750, \n                         mindist = 375)\nMP_lixels <- lixelize_lines(MP_roads, \n                         750, \n                         mindist = 375)\n\n\n\n\nGenerating Line Points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\n\nShow the code\nCA_samples <- lines_center(CA_lixels)\nWL_samples <- lines_center(WL_lixels)\nJE_samples <- lines_center(JE_lixels)\nMP_samples <- lines_center(MP_lixels)\n\n\n\n\nPerforming NetKDE\nWe can now compute the NetKDE using the code chunk below:\n\n\nShow the code\n# for the purposes of this analysis, the bandwidth will be set to 8.080901, which is the diggle bandwidth for Singapore overall\nCA_densities <- nkde(CA_roads, \n                  events = CA_origins,\n                  w = rep(1,nrow(CA_origins)),\n                  samples = CA_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\nJE_densities <- nkde(JE_roads, \n                  events = JE_origins,\n                  w = rep(1,nrow(JE_origins)),\n                  samples = JE_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n # care about bw (bandwith) and kernel_name \n\nWL_densities <- nkde(WL_roads, \n                  events = WL_origins,\n                  w = rep(1,nrow(WL_origins)),\n                  samples = WL_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\nMP_densities <- nkde(MP_roads, \n                  events = MP_origins,\n                  w = rep(1,nrow(MP_origins)),\n                  samples = MP_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\n\n\n\nVisualising NetKDE\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\nShow the code\nCA_samples$density <- CA_densities\nCA_lixels$density <- CA_densities\n\nJE_samples$density <- JE_densities\nJE_lixels$density <- JE_densities\n\nMP_samples$density <- MP_densities\nMP_lixels$density <- MP_densities\n\nWL_samples$density <- WL_densities\nWL_lixels$density <- WL_densities\n\n\nWe can also rescale to make the values more understandable. Since the values are in kilometres, multiplying the values by 1000 will convert them to metres.\nWe can use the code chunk below to visualise the network kernel density estimation:\n\nVisualising NetKDE for Changi\n\n\nShow the code\ntmap_mode('view')\ntm_shape(CA_lixels)+\n  tm_lines(col=\"density\")\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nVisualising NetKDE for Jurong East\n\n\nShow the code\ntmap_mode('view')\ntm_shape(JE_lixels)+\n  tm_lines(col=\"density\")\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nVisualising NetKDE for Marine Parade\n\n\nShow the code\ntmap_mode('view')\ntm_shape(MP_lixels)+\n  tm_lines(col=\"density\")\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nVisualising NetKDE for Woodlands\n\n\nShow the code\ntmap_mode('view')\ntm_shape(WL_lixels)+\n  tm_lines(col=\"density\")\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#traditional-kernel-analysis",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#traditional-kernel-analysis",
    "title": "Take Home Exercise 01",
    "section": "Traditional Kernel Analysis",
    "text": "Traditional Kernel Analysis\nNow we can begin the traditional kernel analysis\n\nCountry level analysis\nWe can begin by trying to find all of the best kernel and bandwidths for the purposes of our analysis. To do this, we need to find the one with the tightest clusters.\nIn R, we have 4 possible kernel density bandwidths: diggle, ppl, scott and CvL. All of them will be test below:\n\n\nShow the code\nkde_origins_SG.bw <- density(origins_SG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_SG.ppl <- density(origins_SG_ppp, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\nkde_origins_SG.CvL <- density(origins_SG_ppp, \n                               sigma=bw.CvL, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\nkde_origins_SG.scott <- density(origins_SG_ppp, \n                               sigma=bw.scott, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\n\nWe may also plot them out:\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(kde_origins_SG.bw)\nplot(kde_origins_SG.ppl)\nplot(kde_origins_SG.CvL)\nplot(kde_origins_SG.scott)\n\n\nNow, we can check for the tightness of these clusters:\n\n\nShow the code\n# tightness of diggle\nbw.diggle(origins_SG_ppp)\n\n# tightness of ppl\nbw.ppl(origins_SG_ppp)\n\n# tightness of CvL\nbw.CvL(origins_SG_ppp)\n\n# tightness of scott\nbw.scott(origins_SG_ppp)\n\n\nWe can observe that the smallest sigma value is from diggle, suggesting that it has the tightest clusters of all the bandwidth. Hence, we will continue using diggle for this analysis.\nWe can also test for different kernels:\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\n\nAs they are identical, there is no need to choose a specific one.\n\n\nRegions of Interest\nWe can tighten our analysis to include only areas of interest. From the figures above, we observe higher densities in the planning areas Changi, Jurong East, Woodlands and Marine Parade, we can filter out mpsz to get them.\n\n\nShow the code\n# extraction of Changi Airport\nCA = mpsz_sf[mpsz_sf$PLN_AREA_N==\"CHANGI\",]\n\n# extraction of Jurong East\nJE = mpsz_sf[mpsz_sf$PLN_AREA_N==\"JURONG EAST\",]\n\n# extraction of Woodlands\nWL = mpsz_sf[mpsz_sf$PLN_AREA_N==\"WOODLANDS\",]\n\n# extraction of Marine Parade\nMP = mpsz_sf[mpsz_sf$PLN_AREA_N=='MARINE PARADE',]\n\n\nWith this, we now have to perform the same functions we did in Create Owin Data.\n\n\nShow the code\n# turn them into spatial\nCA_spatial <- as_Spatial(CA)\nJE_spatial <- as_Spatial(JE)\nWL_spatial <- as_Spatial(WL)\nMP_spatial <- as_Spatial(MP)\n\n# turn them into SpatialPolygons\nCA_sp <- as(CA_spatial, \"SpatialPolygons\")\nJE_sp <- as(JE_spatial, \"SpatialPolygons\")\nWL_sp <- as(WL_spatial, \"SpatialPolygons\")\nMP_sp <- as(MP_spatial, \"SpatialPolygons\")\n\n# convert to owin\n\nCA_owin = as(CA_sp, \"owin\")\nJE_owin = as(JE_sp, \"owin\")\nWL_owin = as(WL_sp, \"owin\")\nMP_owin = as(MP_sp, \"owin\")\n\n\nFrom here, we can extract the events that occurred in these planning areas.\n\n\nShow the code\norigins_CA_ppp = origins_SG_ppp[CA_owin]\norigins_JE_ppp = origins_SG_ppp[JE_owin]\norigins_WL_ppp = origins_SG_ppp[WL_owin]\norigins_MP_ppp = origins_SG_ppp[MP_owin]\n\n\nWe can now perform the same analysis that we did above:\n\n\nShow the code\nkde_origins_CA <- density(origins_CA_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_JE <- density(origins_JE_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_WL <- density(origins_WL_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_MP <- density(origins_MP_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nWe can also plot them out:\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(kde_origins_CA,\n     main=\"Changi\")\nplot(kde_origins_WL,\n     main=\"Woodlands\")\nplot(kde_origins_JE,\n     main=\"Jurong East\")\nplot(kde_origins_MP,\n     main=\"Marine Parade\")"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#clark-and-evans-test",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#clark-and-evans-test",
    "title": "Take Home Exercise 01",
    "section": "Clark and Evans test",
    "text": "Clark and Evans test\nThe Clark and Evans test allows us to understand if the data points are clustered in any places or not.\n\nCountry Level Analysis\nIn the below code chunk, we are conducting this test on the origin points in the whole of Singapore. The hypothesis are as follows\nH0: The Grab origin points are distributed equally throughout the country\nH1: The Grab origin points have clusters.\n\n\nShow the code\nclarkevans.test(origins_SG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_SG_ppp\nR = 0.28039, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\nFrom this, we can see that there is clustering (R=0.28039) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nRegions of Interest\n\nChangi\n\n\nShow the code\nclarkevans.test(origins_CA_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_CA_ppp\nR = 0.13547, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.31778) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nWoodlands\n\n\nShow the code\nclarkevans.test(origins_WL_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_WL_ppp\nR = 0.31778, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.25797) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nJurong East\n\n\nShow the code\nclarkevans.test(origins_JE_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_JE_ppp\nR = 0.25797, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.25797) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nMarine Parade\n\n\nShow the code\nclarkevans.test(origins_MP_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_MP_ppp\nR = 0.51201, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.51201) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, I have learned how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. I have learned how to conduct the following:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\nprovide statistically correct interpretation of GSA statistics.\n\n\n\n\n\n\nOne of the goals of local and government planners is to ensure equal development on a geographic scale. As such, it is important to find out whether or not development is equally distributed, whether there is spatial clustering and finally, where are the clusters located?\nThis hands-on exercise will handle GDP data for the Hunan Province in the Republic of China.\n\n\n\nTwo data sets will be used for this exercise:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is used for importing and handling geospatial data in R,\ntidyverse is mainly used for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\n\nShow the code\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\n\n\n\n\n\n\nShow the code\n# use st_read() from sf package to import Hunan shapefile into R\n# the output is a simple features object of sf\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\nShow the code\n## Import csv into r environment using read_Csv() of sf\n## Output is an R data.frame class\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\n\n\nShow the code\n# update hunan's SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe\n# This is performed using left_join() of dplyr package\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\n\n\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\n\nShow the code\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\nIn this section, I will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\n\nShow the code\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\nShow the code\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\nIn this section, I will be performing Moran’s I statistics testing by using moran.test() of spdep.\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\n\nShow the code\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulations will be performed.\n\n\nShow the code\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\n\nShow the code\nmean(bperm$res[1:999])\n\n\n[1] -0.01504572\n\n\n\n\nShow the code\nvar(bperm$res[1:999])\n\n\n[1] 0.004371574\n\n\n\n\nShow the code\nsummary(bperm$res[1:999])\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\nShow the code\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n(TBC)\n\n\n\n\n\nIn this section, you will learn how to perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\n\nShow the code\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\n\nShow the code\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\n\nShow the code\nmean(bperm$res[1:999])\n\n\n[1] 1.004402\n\n\n\n\nShow the code\nvar(bperm$res[1:999])\n\n\n[1] 0.007436493\n\n\n\n\nShow the code\nsummary(bperm$res[1:999])\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\n\nShow the code\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\n\nShow the code\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\n\nShow the code\nprint(MI_corr)\n\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\n\nShow the code\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\n\nShow the code\nprint(GC_corr)\n\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cluster-and-outlier-analysis",
    "title": "Hands-on Exercise 6",
    "section": "**Cluster and Outlier Analysis",
    "text": "**Cluster and Outlier Analysis\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, I will be applying appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\nComputing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\n\nShow the code\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\n\nShow the code\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nMapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\n\nShow the code\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nMapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\n\nShow the code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\n\nShow the code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\n\nShow the code\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 6",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nPlotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\n\nShow the code\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\nPlotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\n\nShow the code\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% \n  as.vector \n\n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that maps neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\n\nShow the code\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\nPreparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\n\nShow the code\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\n\nNext, derive the spatially lagged variable of interest (i.e. GDPPC) and center the spatially lagged variable around its mean.\n\n\nShow the code\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\n\nThis is followed by centering the local Moran’s around the mean.\n\n\nShow the code\nLM_I <- localMI[,1] - mean(localMI[,1])    \n\n\nNext, we will set a statistical significance level for the local Moran.\n\n\nShow the code\nsignif <- 0.05       \n\n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\n\nShow the code\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4      \n\n\nLastly, places non-significant Moran in the category 0.\n\n\nShow the code\nquadrant[localMI[,5]>signif] <- 0\n\n\n\n\nShow the code\n# combined\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI[,5]>signif] <- 0\n\n\n\n\nPlotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\n\nShow the code\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 6",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\nDeriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\n\nShow the code\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\n\nShow the code\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\n\nShow the code\ncoords <- cbind(longitude, latitude)\n\n\n\n\nDetermine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n\nShow the code\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\n\nShow the code\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\nComputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\n\nShow the code\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow the code\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands-on Exercise 6",
    "section": "Computing Gi Statistics",
    "text": "Computing Gi Statistics\n\nGi Statistics Using Fixed Distance\n\n\nShow the code\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\n\nShow the code\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\nMapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\n\nShow the code\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\nGi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\n\nShow the code\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\nMapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\n\nShow the code\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html",
    "title": "In-class exercise 4",
    "section": "",
    "text": "Remember that the coordinates are in geographic system, not projected\nGood practice to check the data itself\nIRL, GIS analysts will have to clean the data and do the joins\nRead documentation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#loading-of-packages",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#loading-of-packages",
    "title": "In-class exercise 4",
    "section": "Loading of packages",
    "text": "Loading of packages\n\n\nShow the code\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#reading-of-data",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#reading-of-data",
    "title": "In-class exercise 4",
    "section": "Reading of Data",
    "text": "Reading of Data\n\n\nShow the code\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `D:\\KrisLBT\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#import-csv-into-r-environment",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#import-csv-into-r-environment",
    "title": "In-class exercise 4",
    "section": "Import csv into R environment",
    "text": "Import csv into R environment\n\n\nShow the code\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#performing-relational-join",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#performing-relational-join",
    "title": "In-class exercise 4",
    "section": "Performing Relational Join",
    "text": "Performing Relational Join\n\n\nShow the code\n#combines both the hunan and hunan2012 data.frames together\n#subsequently selects certain (2-5, 8 and 16th) columns only\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#visualising-regional-development-indicator",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#visualising-regional-development-indicator",
    "title": "In-class exercise 4",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\n\nShow the code\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\nOutput is list of polygons\nAverage: if the average is not a whole number –> get the rounded value (usually round down)\nRound up for distance\nLat long should be true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#installation-of-package",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#installation-of-package",
    "title": "In-class exercise 4",
    "section": "Installation of Package",
    "text": "Installation of Package\n\n\nShow the code\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#reading-of-data-1",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#reading-of-data-1",
    "title": "In-class exercise 4",
    "section": "Reading of Data",
    "text": "Reading of Data\n\n\nShow the code\nhunan <- st_read(dsn='data/geospatial'\n                 ,layer='Hunan')\n\n\nReading layer `Hunan' from data source \n  `D:\\KrisLBT\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nShow the code\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#modifying-data",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#modifying-data",
    "title": "In-class exercise 4",
    "section": "Modifying Data",
    "text": "Modifying Data\n\n\nShow the code\n#combines both the hunan and hunan2012 data.frames together\n#subsequently selects certain (2-5, 8 and 16th) columns only\n#must do early, otherwise will lose GDP data\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#intro-to-gwmodel",
    "href": "In-class_Ex/In-class_Ex04/In_class_Ex04.html#intro-to-gwmodel",
    "title": "In-class exercise 4",
    "section": "Intro to GWModel",
    "text": "Intro to GWModel\nGWModel –> provide a collection of R libraries that let us use distance matrix to conduct summary statistics, multivariate statistics, discriminant analysis, principal components, logistic regression, multiple linear regression, generalised regression, etc.\nIn this in-class exercise, we will be using GWModel to conduct summary statistics.\n\nWorking with GWSS\n\n\n\n\n\n\nThis package cannot accept SF, must be sp object class\n\n\n\n\n\n\n\n\nShow the code\nhunan_sp <- hunan %>%\n  as_Spatial()\n\n\nThe adaptive bandwith has to be number of neighbours (bw).\nCan take in multiple variables., at the same time (vars)\n\n\nShow the code\ngwstat <- gwss(data=hunan_sp,\n               vars=\"GDPPC\",\n               bw=6,\n               kernel='bisquare',\n               adaptive=TRUE,\n               longlat=T)\n\n\nGDPPC_LM is the same as the application of spatial lag (specifically the distance matrix).\nmean, standard deviation, variance, skew, coefficience of variations.\nView(gwstat[[\"SDF\"]]@data) --> to view"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#exploratory-data-analysis-and-handling-of-origins",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#exploratory-data-analysis-and-handling-of-origins",
    "title": "Take Home Exercise 01: Part 1",
    "section": "Exploratory Data Analysis and Handling of Origins",
    "text": "Exploratory Data Analysis and Handling of Origins\nIn this section, I will be exploring the general distribution of the origin points and handling it for the subsequent sections, which will analyse the data in greater detail.\n\nVisualising the Frequency Distribution\nFirst, I will plot out the general distribution of the origin points\n\n\nShow the code\nggplot(data=origin_df,\n       aes(x=weekday)) +\n  geom_bar()\n\n\n\n\n\nAs can be seen, the number of trips daily seem to be fairly equally distributed throughout the week.\n\n\nVisualising the Origins as a Point Map Symbol\nWe can visualise the geospatial distribution of the origin points. First, we need to convert the coordinates to lat-long and transform it to the correct CRS.\n\n\nShow the code\norigins_sf <- st_as_sf(origin_df, coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %>%\n  st_transform(crs=3414)\n\n\nNow, we can visualise it using the code chunk below:\n\n\nShow the code\ntm_shape(mpsz_sf)+\n  tm_polygons()+\ntm_shape(origins_sf) +\n  tm_dots()\n\n\n\n\nHandling\nFor further analysis, we will need to convert the various data into different formats. These will be explained and performed in the code chunk below\n\n\nShow the code\n#conversion of sg_sf, mpsz_sf and origins_sf to a generic spatial class\nsg <- as_Spatial(sg_sf)\nmpsz <- as_Spatial(mpsz_sf)\norigins <- as_Spatial(origins_sf) \n\n# Conversion of sg and origins to SpatialPolygon format\nsg_sp <- as(sg, \"SpatialPolygons\")\norigins_sp <- as(origins, \"SpatialPoints\")\n\n# conversion of origins to ppp format\norigins_ppp <- as(origins_sp, \"ppp\")\norigins_ppp\n\n\nPlanar point pattern: 28000 points\nwindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n\n\nNow, I will plot origins_ppp.\n\n\nShow the code\nplot(origins_ppp)\n\n\nWe must check for duplicates in the data using the code chunk below:\n\n\nShow the code\nany(duplicated(origins_ppp))\n\n\n[1] FALSE\n\n\nAs there are no duplicates within the data, we do not have to apply any more transformation to the data.\n\nCreate Owin Data\nNow, we can convert the Coastal Outline to owin data and plot it out.\n\n\nShow the code\nsg_owin <- as(sg_sp, \"owin\")\nplot(sg_owin)\n\n\n\n\n\n\n\nCombining Events\nWe will now extract Grab origins within the Singapore CoastalOutline\n\n\nShow the code\norigins_SG_ppp = origins_ppp[sg_owin]\n\n# plotting the distribution of the origins\nplot(origins_SG_ppp)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#country-level-analysis",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#country-level-analysis",
    "title": "Take Home Exercise 01",
    "section": "Country Level Analysis",
    "text": "Country Level Analysis\nWe can begin by trying to find all of the best kernel and bandwidths for the purposes of our analysis. To do this, we need to find the one with the tightest clusters.\nIn R, we have 4 possible kernel density bandwidths: diggle, ppl, scott and CvL. All of them will be tested below:\n\n\nShow the code\n# diggle\nkde_origins_SG.bw <- density(origins_SG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n# ppl\nkde_origins_SG.ppl <- density(origins_SG_ppp, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n# CvL\nkde_origins_SG.CvL <- density(origins_SG_ppp, \n                               sigma=bw.CvL, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n# scott\nkde_origins_SG.scott <- density(origins_SG_ppp, \n                               sigma=bw.scott, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\n\nWe may also plot them out:\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(kde_origins_SG.bw)\nplot(kde_origins_SG.ppl)\nplot(kde_origins_SG.CvL)\nplot(kde_origins_SG.scott)\n\n\nNow, we can check for the tightness of these clusters:\n\n\nShow the code\n# tightness of diggle\nbw.diggle(origins_SG_ppp)\n\n# tightness of ppl\nbw.ppl(origins_SG_ppp)\n\n# tightness of CvL\nbw.CvL(origins_SG_ppp)\n\n# tightness of scott\nbw.scott(origins_SG_ppp)\n\n\nWe can observe that the smallest sigma value is from diggle, suggesting that it has the tightest clusters of all the bandwidth. Hence, we will continue using diggle for this analysis.\nWe can also test for different kernels:\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(origins_SG_ppp, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\n\nAs they are identical, there is no need to choose a specific one. Moving forward, I will be using Gaussian kernel."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#regions-of-interest",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01.html#regions-of-interest",
    "title": "Take Home Exercise 01",
    "section": "Regions of Interest",
    "text": "Regions of Interest\nWe can tighten our analysis to include only areas of interest. From the figures above, we observe higher densities in the planning areas Changi, Jurong East, Woodlands and Marine Parade, we can filter out mpsz to get them.\n\n\nShow the code\n# extraction of Changi Airport\nCA = mpsz_sf[mpsz_sf$PLN_AREA_N==\"CHANGI\",]\n\n# extraction of Jurong East\nJE = mpsz_sf[mpsz_sf$PLN_AREA_N==\"JURONG EAST\",]\n\n# extraction of Woodlands\nWL = mpsz_sf[mpsz_sf$PLN_AREA_N==\"WOODLANDS\",]\n\n# extraction of Marine Parade\nMP = mpsz_sf[mpsz_sf$PLN_AREA_N=='MARINE PARADE',]\n\n\nWith this, we now have to perform the same functions we did in Create Owin Data and Conversions.\n\n\nShow the code\n# turn them into spatial\nCA_spatial <- as_Spatial(CA)\nJE_spatial <- as_Spatial(JE)\nWL_spatial <- as_Spatial(WL)\nMP_spatial <- as_Spatial(MP)\n\n# turn them into SpatialPolygons\nCA_sp <- as(CA_spatial, \"SpatialPolygons\")\nJE_sp <- as(JE_spatial, \"SpatialPolygons\")\nWL_sp <- as(WL_spatial, \"SpatialPolygons\")\nMP_sp <- as(MP_spatial, \"SpatialPolygons\")\n\n# convert to owin\n\nCA_owin = as(CA_sp, \"owin\")\nJE_owin = as(JE_sp, \"owin\")\nWL_owin = as(WL_sp, \"owin\")\nMP_owin = as(MP_sp, \"owin\")\n\n\nFrom here, we can extract the events that occurred in these planning areas.\n\n\nShow the code\norigins_CA_ppp = origins_SG_ppp[CA_owin]\norigins_JE_ppp = origins_SG_ppp[JE_owin]\norigins_WL_ppp = origins_SG_ppp[WL_owin]\norigins_MP_ppp = origins_SG_ppp[MP_owin]\n\n\nWe can now perform the same analysis that we did in Country Level Analysis:\n\n\nShow the code\nkde_origins_CA <- density(origins_CA_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_JE <- density(origins_JE_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_WL <- density(origins_WL_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_origins_MP <- density(origins_MP_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nWe can also plot them out:\n\n\nShow the code\npar(mfrow=c(2,2))\nplot(kde_origins_CA,\n     main=\"Changi\")\nplot(kde_origins_WL,\n     main=\"Woodlands\")\nplot(kde_origins_JE,\n     main=\"Jurong East\")\nplot(kde_origins_MP,\n     main=\"Marine Parade\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "",
    "text": "For this in-class exercise, we will be using the following packages and loading it into our R environment:\n\nsf\ntmap\nsfdep\n\nthe newer version of spdep;\ncan use immediately with sf objects; will save to sf layer) – old version had to extract it out\n\ntidyverse\n\n\n\nShow the code\npacman::p_load(sf, tmap, sfdep, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#importing-geospatial-data",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nFirst, I will be importing Hunan.\n\n\nShow the code\nHunan <- st_read(dsn=\"data/geospatial\",\n                 layer = \"Hunan\") \n\n\nReading layer `Hunan' from data source \n  `D:\\KrisLBT\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nCheck if the bounding box is in decimal deree or not. If it’s in decimal degree, it is in geodetic CRS, not projected CRS."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#importing-aspatial-data",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#importing-aspatial-data",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\nNow, I will be importing Hunan_2012.csv into my R environment\n\n\nShow the code\nHunan_2012 = read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#joining-the-data",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#joining-the-data",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Joining the Data",
    "text": "Joining the Data\n\n\nShow the code\n# will lose geometry for sf layer\nhunan_GDPPC <- left_join(Hunan, Hunan_2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#notes",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#notes",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Notes",
    "text": "Notes\nCheck if anything can be used to join the data frames (geospatial and aspatial). This can be County name etc.\nAlso, perform left_join to prevent losing the geometric data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#note-1",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#note-1",
    "title": "In-class Exercise 05",
    "section": "Note",
    "text": "Note\n.before = 1 means to ensure one column will always be the first May not be necessaryin real life applications"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#computing-global-moran-i",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#computing-global-moran-i",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Computing Global Moran I",
    "text": "Computing Global Moran I\n\n\nShow the code\nmoranI <- global_moran(wm_q$GDPPC,\n                      wm_q$nb,\n                      wm_q$wt)\nglimpse(moranI)\n\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nHowever, Global Moran I might not be convincing enough"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#queenss-method",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#queenss-method",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Queens’s Method",
    "text": "Queens’s Method\nYou can go directly into the Queen’s Method using tidyverse in a singular step:\n\n\nShow the code\nwm_q <- hunan_GDPPC %>%\n  mutate(nb=st_contiguity(geometry),\n         wt= st_weights(nb,\n                        style = \"W\"),\n         .before =1)\n\n\n\nNote\n.before = 1 means to ensure one column will always be the first May not be necessary in real life applications"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#performing-global-moran-i-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In_class_Ex05.html#performing-global-moran-i-permutation-test",
    "title": "In-class Exercise 05 - Global and Local Measures of Spatial Association: sfdep method",
    "section": "Performing Global Moran I permutation test",
    "text": "Performing Global Moran I permutation test\nCan do it on multiple simulations (in this case 100. This is because the number of simulations is nsim+1) to confirm the representativeness of the data set.\n\n\nShow the code\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe statistical report above demonstrates that the p-value is smaller than 0.05, which means that this result is significant at a 95% significance level. Hence, we can reject the null hypothesis that the spatial distribution of GDP per capita resembles random distribution. Because the Moran’s I value is greater than 0, we can infer that the spatial distribution shows signs of clustering.\n\nNote\nnsim will effect computation time. If you’re on a larger data set, you can just do a smaller number (e.g. 99, 49). 999 may take an incredibly long time to load. Test if your compute can handle it within a certain timeframe.\nWe can also only infer from the results, we can’t definitively prove/disprove our hypothesis\n\nComplete in-class exercise 5 on our own + watch video for hot and cold spot"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html",
    "title": "Take Home Exercise 01: Part 2",
    "section": "",
    "text": "Show the code\n#loading the packages\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse, arrow, lubridate, spNetwork, classInt)\n\n\n\n\n\n\n\nShow the code\n# data\n\n# reading the Singapore Master Plan\nmpsz_sf <- st_read(dsn = \"../../data/data\",\n                layer = \"MP14_SUBZONE_WEB_PL\") %>%\n  st_transform(3414)\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\KrisLBT\\IS415-GAA\\data\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nShow the code\n# reading the CoastalOutline\nsg_sf <- st_read(dsn='data/',\n                 layer = \"CoastalOutline\")\n\n\nReading layer `CoastalOutline' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21494.3 xmax: 55941.94 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\nShow the code\n# reading the origin points\norigin_df <- read_rds(\"data/rds/origin_dfs.rds\")"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#country-level-analysis",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#country-level-analysis",
    "title": "Take Home Exercise 01: Part 2",
    "section": "Country Level Analysis",
    "text": "Country Level Analysis\nWe can begin by trying to find all of the best kernel and bandwidths for the purposes of our analysis. To do this, we need to find the one with the tightest clusters.\nIn R, we have 4 possible kernel density bandwidths: diggle, ppl, scott and CvL. All of them will be tested below:\n\n\nShow the code\n#diggle \nkde_origins_SG.bw <- density(origins_SG_ppp, \n                             sigma=bw.diggle,\n                             edge=TRUE,\n                             kernel=\"gaussian\")  \n# ppl \nkde_origins_SG.ppl <- density(origins_SG_ppp,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                              kernel=\"gaussian\") \n# CvL \nkde_origins_SG.CvL <- density(origins_SG_ppp,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                              kernel=\"gaussian\") \n# scott \nkde_origins_SG.scott <- density(origins_SG_ppp,\n                                sigma=bw.scott, \n                                edge=TRUE,\n                                kernel=\"gaussian\")\n\n\nWe may also plot them out:\n\n\nShow the code\npar(mfrow=c(2,2)) \nplot(kde_origins_SG.bw) \nplot(kde_origins_SG.ppl) \nplot(kde_origins_SG.CvL) \nplot(kde_origins_SG.scott)\n\n\nNow, we can check for the tightness of these clusters:\n\n\nShow the code\n# tightness of diggle \nbw.diggle(origins_SG_ppp)  \n# tightness of ppl \nbw.ppl(origins_SG_ppp)  \n# tightness of CvL \nbw.CvL(origins_SG_ppp)  \n# tightness of scott \nbw.scott(origins_SG_ppp) \n\n\nWe can observe that the smallest sigma value is from diggle, suggesting that it has the tightest clusters of all the bandwidth. Hence, we will continue using diggle for this analysis.\nWe can also test for different kernels:\n\n\nShow the code\npar(mfrow=c(2,2)) \nplot(density(origins_SG_ppp,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Gaussian\") \nplot(density(origins_SG_ppp,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"epanechnikov\"),\n     main=\"Epanechnikov\") \nplot(density(origins_SG_ppp,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"quartic\"),\n     main=\"Quartic\") \nplot(density(origins_SG_ppp,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"disc\"),\n     main=\"Disc\") \n\n\n\n\n\nAs they are identical, there is no need to choose a specific one. Moving forward, I will be using Gaussian kernel."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#regions-of-interest",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#regions-of-interest",
    "title": "Take Home Exercise 01: Part 2",
    "section": "Regions of Interest",
    "text": "Regions of Interest\nWe can tighten our analysis to include only areas of interest. From the figures above, we observe higher densities in the planning areas Changi, Jurong East, Woodlands and Marine Parade, we can filter out mpsz to get them.\n\n\nShow the code\n# extraction of Changi Airport \nCA = mpsz_sf[mpsz_sf$PLN_AREA_N==\"CHANGI\",]  \n# extraction of Jurong East \nJE = mpsz_sf[mpsz_sf$PLN_AREA_N==\"JURONG EAST\",]  \n# extraction of Woodlands \nWL = mpsz_sf[mpsz_sf$PLN_AREA_N==\"WOODLANDS\",]  \n# extraction of Marine Parade \nMP = mpsz_sf[mpsz_sf$PLN_AREA_N=='MARINE PARADE',]\n\n\nWith this, we now have to perform the same functions we did in Create Owin Data and Conversions.\n\n\nShow the code\n# turn them into spatial \nCA_spatial <- as_Spatial(CA)\nJE_spatial <- as_Spatial(JE)\nWL_spatial <- as_Spatial(WL)\nMP_spatial <- as_Spatial(MP)  \n\n# turn them into SpatialPolygons \nCA_sp <- as(CA_spatial, \"SpatialPolygons\") \nJE_sp <- as(JE_spatial, \"SpatialPolygons\") \nWL_sp <- as(WL_spatial, \"SpatialPolygons\") \nMP_sp <- as(MP_spatial, \"SpatialPolygons\")  \n\n# convert to owin  \nCA_owin = as(CA_sp, \"owin\") \nJE_owin = as(JE_sp, \"owin\") \nWL_owin = as(WL_sp, \"owin\") \nMP_owin = as(MP_sp, \"owin\")\n\n\nFrom here, we can extract the events that occurred in these planning areas.\n\n\nShow the code\norigins_CA_ppp = origins_SG_ppp[CA_owin] \norigins_JE_ppp = origins_SG_ppp[JE_owin] \norigins_WL_ppp = origins_SG_ppp[WL_owin]\norigins_MP_ppp = origins_SG_ppp[MP_owin]\n\n\nWe can now perform the same analysis that we did in Country Level Analysis:\n\n\nShow the code\nkde_origins_CA <- density(origins_CA_ppp,\n                          sigma=bw.diggle,\n                          edge=TRUE,\n                          kernel=\"gaussian\")  \nkde_origins_JE <- density(origins_JE_ppp,\n                          sigma=bw.diggle,\n                          edge=TRUE, \n                          kernel=\"gaussian\")  \nkde_origins_WL <- density(origins_WL_ppp,\n                          sigma=bw.diggle,\n                          edge=TRUE,\n                          kernel=\"gaussian\")  \nkde_origins_MP <- density(origins_MP_ppp,\n                          sigma=bw.diggle,\n                          edge=TRUE,\n                          kernel=\"gaussian\") \n\n\nWe can also plot them out:\n\n\nShow the code\npar(mfrow=c(2,2)) \nplot(kde_origins_CA,\n     main=\"Changi\") \nplot(kde_origins_WL,\n     main=\"Woodlands\")\nplot(kde_origins_JE,\n     main=\"Jurong East\")\nplot(kde_origins_MP,\n     main=\"Marine Parade\")"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#clark-and-evans-test",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#clark-and-evans-test",
    "title": "Take Home Exercise 01: Part 2",
    "section": "Clark and Evans test",
    "text": "Clark and Evans test\nThe Clark and Evans test allows us to understand if the data points are clustered in any places or not.\n\nCountry Level Analysis\nIn the below code chunk, we are conducting this test on the origin points in the whole of Singapore. The hypothesis are as follows\nH0: The Grab origin points are distributed equally throughout the country\nH1: The Grab origin points have clusters.\n\n\nShow the code\nclarkevans.test(origins_SG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_SG_ppp\nR = 0.28039, p-value < 2.2e-16\nalternative hypothesis: clustered (R < 1)\n\n\nFrom this, we can see that there is clustering (R=0.28039) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nRegions of Interest\n\nChangi\n\n\nShow the code\nclarkevans.test(origins_CA_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_CA_ppp\nR = 0.13547, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.31778) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nWoodlands\n\n\nShow the code\nclarkevans.test(origins_WL_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_WL_ppp\nR = 0.31778, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.25797) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nJurong East\n\n\nShow the code\nclarkevans.test(origins_JE_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_JE_ppp\nR = 0.25797, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.25797) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters.\n\n\nMarine Parade\n\n\nShow the code\nclarkevans.test(origins_MP_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origins_MP_ppp\nR = 0.51201, p-value < 2.2e-16\nalternative hypothesis: two-sided\n\n\nFrom this, we can see that there is clustering (R= 0.51201) at a p-value of 2.2e-16. As 2.2e-16 is smaller than 0.05, we can conclude that this difference is significant at a 5% significance level. Hence, we reject the null hypothesis and the Grab origin points have clusters."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#data-handling-1",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#data-handling-1",
    "title": "Take Home Exercise 01: Part 2",
    "section": "Data Handling",
    "text": "Data Handling\n\nHandling of Road Data\nNow, we can read the road data as provided by openstreetmap. Note that it provides data for Malaysia, Singapore and Brunei all at once.\n\n\nShow the code\nall_roads <- st_read(dsn='../../data/data/data',\n                     layer = 'gis_osm_roads_free_1')\n\n\nWe realise that it is in WGS 84, not in SVY21 so we have to transform the data.\n\n\nShow the code\nall_roads <- st_transform(all_roads, 3414)\n\n\nWe can check the CRS again for all_roads.\n\n\nShow the code\nst_crs(all_roads)\n\n\nSince we’re only interested in the roads in mainland Singapore, we have to filter the roads.\n\n\nShow the code\n# get all roads in mainland Singapore \nSG_roads <- st_intersection(all_roads, sg_sf)  \n# write out the roads into a separate .shp file for easier future handling \nst_write(SG_roads, 'data/SG_roads.shp')\n\n\nWe can now read it from here.\n\n\nShow the code\nSG_roads <- st_read(dsn='data', layer= 'SG_roads')\n\n\nReading layer `SG_roads' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_1\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 227969 features and 10 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 2679.373 ymin: 23099.51 xmax: 50957.8 ymax: 50220.06\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\nGetting the Roads within the Subzones\nNow, we can find the streets that exist only inside the subzones.\n\n\nShow the code\n# get roads only in the aforementioned subzones \nCA_roads <- st_intersection(SG_roads, CA) \nWL_roads <- st_intersection(SG_roads, WL) \nJE_roads <- st_intersection(SG_roads, JE) \nMP_roads <- st_intersection(SG_roads, MP)\n\n\n\n\nShow the code\nCA_roads\n\n\nSimple feature collection with 4007 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 42577.65 ymin: 32548.05 xmax: 50286.8 ymax: 41649.2\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code      fclass                  name  ref oneway maxspeed layer\n356  22617051 5113     primary         Loyang Avenue <NA>      F       70     0\n360  22617159 5113     primary         Loyang Avenue <NA>      F       70     0\n1348 22981700 5113     primary       Telok Paku Road <NA>      F       50     0\n3201 34403286 5114   secondary            Loyang Way <NA>      F       50     0\n3207 34403387 5122 residential Changi North Street 1 <NA>      B        0     0\n3208 34403405 5122 residential Changi North Crescent <NA>      B       50     0\n3209 34403417 5122 residential     Changi North Rise <NA>      B        0     0\n4001 42063713 5141     service                  <NA> <NA>      F        0     0\n4002 42063715 5141     service                  <NA> <NA>      B        0     0\n4003 42063716 5141     service                  <NA> <NA>      B        0     0\n     bridge tunnel OBJECTID SUBZONE_NO   SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N\n356       F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n360       F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n1348      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3201      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3207      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3208      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n3209      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n4001      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n4002      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n4003      F      F      221          2 CHANGI WEST    CHSZ02      N     CHANGI\n     PLN_AREA_C    REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n356          CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n360          CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n1348         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3201         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3207         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3208         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n3209         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n4001         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n4002         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n4003         CH EAST REGION       ER 7460F2CFB1D7D36C 2014-12-05 44092.34\n       Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n356  38928.66   14918.11    4848517 LINESTRING (44617.88 41088....\n360  38928.66   14918.11    4848517 LINESTRING (43851.2 39632.9...\n1348 38928.66   14918.11    4848517 LINESTRING (45352.67 41113....\n3201 38928.66   14918.11    4848517 LINESTRING (43761.28 39560....\n3207 38928.66   14918.11    4848517 LINESTRING (43152.23 36906....\n3208 38928.66   14918.11    4848517 LINESTRING (42843.89 36842....\n3209 38928.66   14918.11    4848517 LINESTRING (43130.89 36812....\n4001 38928.66   14918.11    4848517 LINESTRING (43433.23 37663....\n4002 38928.66   14918.11    4848517 LINESTRING (43436.11 37657....\n4003 38928.66   14918.11    4848517 LINESTRING (43511.5 37906.7...\n\n\nShow the code\nWL_roads \n\n\nSimple feature collection with 7165 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 20613.4 ymin: 44814.83 xmax: 25593.19 ymax: 49200.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code        fclass                name  ref oneway maxspeed layer\n796  22773625 5115      tertiary  Woodlands Avenue 6 <NA>      F       40     0\n819  22774351 5131 motorway_link                <NA> <NA>      F       50     0\n825  22774532 5122   residential  Woodlands Drive 14 <NA>      F       40     0\n826  22774537 5122   residential  Woodlands Drive 53 <NA>      B       50     0\n827  22774541 5122   residential  Woodlands Drive 43 <NA>      F       40     0\n832  22775173 5115      tertiary  Woodlands Avenue 5 <NA>      F       60     0\n834  22775385 5113       primary Woodlands Avenue 12 <NA>      F       70     0\n835  22775386 5114     secondary  Woodlands Avenue 1 <NA>      F       50     0\n836  22775389 5114     secondary  Woodlands Avenue 1 <NA>      F       50     0\n3703 37584630 5111      motorway  Seletar Expressway  SLE      F       90     1\n     bridge tunnel OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND\n796       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n819       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n825       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n826       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n827       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n832       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n834       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n835       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n836       F      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n3703      T      F      282          4 WOODLANDS SOUTH    WDSZ04      N\n     PLN_AREA_N PLN_AREA_C     REGION_N REGION_C          INC_CRC FMEL_UPD_D\n796   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n819   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n825   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n826   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n827   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n832   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n834   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n835   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n836   WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n3703  WOODLANDS         WD NORTH REGION       NR 8A4E14DAC4ACE11C 2014-12-05\n       X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n796  23609.57 45692.88   5211.384    1576001 LINESTRING (24007.3 45538.1...\n819  23609.57 45692.88   5211.384    1576001 LINESTRING (22821.47 45515....\n825  23609.57 45692.88   5211.384    1576001 LINESTRING (23444.28 46022....\n826  23609.57 45692.88   5211.384    1576001 LINESTRING (23990.45 46088....\n827  23609.57 45692.88   5211.384    1576001 LINESTRING (23447.47 46014....\n832  23609.57 45692.88   5211.384    1576001 LINESTRING (24645.58 46021....\n834  23609.57 45692.88   5211.384    1576001 LINESTRING (23836.85 45038....\n835  23609.57 45692.88   5211.384    1576001 LINESTRING (23124.88 45989....\n836  23609.57 45692.88   5211.384    1576001 LINESTRING (24156.4 45407.0...\n3703 23609.57 45692.88   5211.384    1576001 LINESTRING (23684.88 44959....\n\n\nShow the code\nJE_roads \n\n\nSimple feature collection with 7131 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 14254.68 ymin: 30994.22 xmax: 19398.25 ymax: 37289.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code       fclass                     name  ref oneway maxspeed\n1084 22903885 5114    secondary             Penjuru Road <NA>      F       60\n1085 22903886 5121 unclassified             Penjuru Road <NA>      F       60\n1443 23101520 5112        trunk              Jalan Buroh <NA>      F       70\n3791 39959160 5112        trunk              Jalan Buroh <NA>      F       70\n3792 39959161 5112        trunk              Jalan Buroh <NA>      F       70\n5003 70583774 5115     tertiary              Pandan Road <NA>      B       50\n5004 70583780 5121 unclassified             Penjuru Lane <NA>      B       50\n5005 70583783 5114    secondary          Tanjong Penjuru <NA>      B       50\n5006 70583786 5114    secondary          Tanjong Penjuru <NA>      F       50\n5007 70583790 5121 unclassified Tanjong Penjuru Crescent <NA>      B       50\n     layer bridge tunnel OBJECTID SUBZONE_NO        SUBZONE_N SUBZONE_C CA_IND\n1084     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n1085     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n1443     1      T      F       80         10 PENJURU CRESCENT    JESZ10      N\n3791     1      T      F       80         10 PENJURU CRESCENT    JESZ10      N\n3792     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5003     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5004     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5005     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5006     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n5007     0      F      F       80         10 PENJURU CRESCENT    JESZ10      N\n      PLN_AREA_N PLN_AREA_C    REGION_N REGION_C          INC_CRC FMEL_UPD_D\n1084 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n1085 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n1443 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n3791 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n3792 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5003 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5004 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5005 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5006 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n5007 JURONG EAST         JE WEST REGION       WR BC263278706376DE 2014-12-05\n       X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1084 17651.31 31799.61   9876.049    3049720 LINESTRING (16991.44 32621....\n1085 17651.31 31799.61   9876.049    3049720 LINESTRING (16738.48 31589....\n1443 17651.31 31799.61   9876.049    3049720 LINESTRING (16290.72 32753....\n3791 17651.31 31799.61   9876.049    3049720 LINESTRING (19056.98 32186....\n3792 17651.31 31799.61   9876.049    3049720 LINESTRING (18978.73 32113....\n5003 17651.31 31799.61   9876.049    3049720 LINESTRING (18411.82 31559....\n5004 17651.31 31799.61   9876.049    3049720 LINESTRING (17208.01 32320....\n5005 17651.31 31799.61   9876.049    3049720 LINESTRING (16869.64 32131....\n5006 17651.31 31799.61   9876.049    3049720 LINESTRING (17506.95 32049....\n5007 17651.31 31799.61   9876.049    3049720 LINESTRING (17697.91 31764....\n\n\nShow the code\nMP_roads\n\n\nSimple feature collection with 2864 features and 25 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 32697.12 ymin: 29763 xmax: 37589.95 ymax: 32843.37\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n       osm_id code       fclass                         name  ref oneway\n922  22810641 5114    secondary    Tanjong Katong Road South <NA>      F\n1202 22930502 5113      primary            Marina East Drive <NA>      F\n3760 39477475 5111     motorway           East Coast Parkway  ECP      F\n3761 39477476 5111     motorway           East Coast Parkway  ECP      F\n4078 44122367 5152     cycleway               Park Connector <NA>      B\n4097 44133236 5153      footway      Underpass to Meyer Road <NA>      B\n4140 44488255 5153      footway                  Katong Park <NA>      B\n4141 44488257 5121 unclassified East Coast Park Service Road <NA>      B\n4142 44488265 5114    secondary    Tanjong Katong Road South <NA>      F\n5509 74729034 5111     motorway           East Coast Parkway  ECP      F\n     maxspeed layer bridge tunnel OBJECTID SUBZONE_NO        SUBZONE_N\n922        50     0      F      F       44          5 MARINA EAST (MP)\n1202       60     0      F      F       44          5 MARINA EAST (MP)\n3760       90     1      T      F       44          5 MARINA EAST (MP)\n3761       80     0      F      F       44          5 MARINA EAST (MP)\n4078        0     0      F      F       44          5 MARINA EAST (MP)\n4097        0    -1      F      T       44          5 MARINA EAST (MP)\n4140        0    -1      F      T       44          5 MARINA EAST (MP)\n4141       50     0      F      F       44          5 MARINA EAST (MP)\n4142       50     1      T      F       44          5 MARINA EAST (MP)\n5509       90     0      F      F       44          5 MARINA EAST (MP)\n     SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C       REGION_N REGION_C\n922     MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n1202    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n3760    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n3761    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4078    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4097    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4140    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4141    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n4142    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n5509    MPSZ05      N MARINE PARADE         MP CENTRAL REGION       CR\n              INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR SHAPE_Leng SHAPE_Area\n922  1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n1202 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n3760 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n3761 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4078 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4097 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4140 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4141 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n4142 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n5509 1575868DF0D30E32 2014-12-05 33715.7 30512.25   6657.151    1590340\n                           geometry\n922  LINESTRING (35230.6 31057.3...\n1202 LINESTRING (33760.43 30638....\n3760 LINESTRING (33860.36 30899....\n3761 LINESTRING (33706.71 30894....\n4078 LINESTRING (34789.2 30864.6...\n4097 LINESTRING (34772.07 30914....\n4140 LINESTRING (34005.49 30906....\n4141 LINESTRING (35255.73 30985,...\n4142 LINESTRING (35227.24 31091....\n5509 LINESTRING (34854.12 30932....\n\n\nWe notice that all of the above are geometry type geometry and not a linestring. We can convert them with the following code chunk:\n\n\nShow the code\nCA_roads <- CA_roads %>%   \n  st_cast(\"LINESTRING\")  \nWL_roads <- WL_roads %>%   \n  st_cast(\"LINESTRING\")  \nJE_roads <- JE_roads %>%   \n  st_cast(\"LINESTRING\")  \nMP_roads <- MP_roads %>%   \n  st_cast(\"LINESTRING\")\n\n\n\n\nExtraction of the Events Within the Subzones\nBefore we can conduct analysis on the network, we will also need to constrict the events to exclusively the ones that occurred within these two subzones.\n\n\nShow the code\n #extraction of origin events that occurred within Changi and Marine Parade \nCA_origins <- st_intersection(origins_sf, CA) \nWL_origins <- st_intersection(origins_sf, WL) \nJE_origins <- st_intersection(origins_sf, JE) \nMP_origins <- st_intersection(origins_sf, MP) \n\n\nWe can now plot this data. In this instance, we can use Changi as an example:\n\n\nShow the code\ntmap_mode('view') \ntm_shape(CA_origins)+ \n  tm_dots() + \n  tm_shape(CA_roads) +\n  tm_lines()\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#network-constrained-kde-netkde-analysis",
    "href": "Take_Home_Exercises/Take_Home_Exercise_1/Take_Home_Exercise_01P2.html#network-constrained-kde-netkde-analysis",
    "title": "Take Home Exercise 01: Part 2",
    "section": "Network Constrained KDE (NetKDE) Analysis",
    "text": "Network Constrained KDE (NetKDE) Analysis\n\nPreparing the lixel objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\n\nShow the code\nCA_lixels <- lixelize_lines(CA_roads,\n                            750,\n                            mindist = 375) \nWL_lixels <- lixelize_lines(WL_roads,\n                            750,\n                            mindist = 375) \nJE_lixels <- lixelize_lines(JE_roads,\n                            750,\n                            mindist = 375) \nMP_lixels <- lixelize_lines(MP_roads,\n                            750,\n                            mindist = 375)\n\n\n\n\nGenerating Line Points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\n\nShow the code\nCA_samples <- lines_center(CA_lixels) \nWL_samples <- lines_center(WL_lixels) \nJE_samples <- lines_center(JE_lixels) \nMP_samples <- lines_center(MP_lixels)\n\n\n\n\nPerforming NetKDE\nWe can now compute the NetKDE using the code chunk below:\n\n\nShow the code\n# for the purposes of this analysis, the bandwidth will be set to 8.080901, which is the diggle bandwidth for Singapore overall \nCA_densities <- nkde(CA_roads, \n                  events = CA_origins,\n                  w = rep(1,nrow(CA_origins)),\n                  samples = CA_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\nJE_densities <- nkde(JE_roads, \n                  events = JE_origins,\n                  w = rep(1,nrow(JE_origins)),\n                  samples = JE_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n # care about bw (bandwith) and kernel_name \n\nWL_densities <- nkde(WL_roads, \n                  events = WL_origins,\n                  w = rep(1,nrow(WL_origins)),\n                  samples = WL_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\nMP_densities <- nkde(MP_roads, \n                  events = MP_origins,\n                  w = rep(1,nrow(MP_origins)),\n                  samples = MP_samples,\n                  kernel_name = \"quartic\",\n                  bw = 8.080901, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 10, #we aggregate events within a 10m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n# care about bw (bandwith) and kernel_name \n\n\n\n\nVisualising NetKDE\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\nShow the code\nCA_samples$density <- CA_densities\nCA_lixels$density <- CA_densities\n\nJE_samples$density <- JE_densities\nJE_lixels$density <- JE_densities\n\nMP_samples$density <- MP_densities\nMP_lixels$density <- MP_densities\n\nWL_samples$density <- WL_densities\nWL_lixels$density <- WL_densities\n\n\nWe can also rescale to make the values more understandable. Since the values are in kilometres, multiplying the values by 1000 will convert them to metres.\nWe can use the code chunk below to visualise the network kernel density estimation:\n\nVisualising NetKDE for Changi\n\n\nShow the code\ntmap_mode('view')\ntm_shape(CA_lixels)+\n  tm_lines(col=\"density\")\n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nVisualising NetKDE for Jurong East\n\n\nShow the code\ntmap_mode('view') \ntm_shape(JE_lixels)+   \n  tm_lines(col=\"density\")  \n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nVisualising NetKDE for Marine Parade\n\n\nShow the code\ntmap_mode('view') \ntm_shape(MP_lixels)+   \n  tm_lines(col=\"density\")  \n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')\n\n\n\n\nVisualising NetKDE for Woodlands\n\n\nShow the code\ntmap_mode('view') \ntm_shape(WL_lixels)+   \n  tm_lines(col=\"density\")  \n\n\n\n\n\n\n\nShow the code\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "I did this exercise by accident in week 3: Please refer to this site for my work for it"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html",
    "title": "Take Home Exercise 02",
    "section": "",
    "text": "From prof:\nAs a curious geospatial analytics green horn, you are interested to discover:\n\nif the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from space and space and time.\nIf the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\na study area layer in sf polygon features. It must be at village level and confined to the D01, D02, D04, D06, D07, D08, D32 and D39 counties of Tainan City, Taiwan.\na dengue fever layer within the study area in sf point features. The dengue fever cases should be confined to epidemiology week 31-50, 2023.\na derived dengue fever layer in spacetime s3 class of sfdep. It should contain, among many other useful information, a data field showing number of dengue fever cases by village and by epidemiology week.\n\nUsing the extracted data, perform global spatial autocorrelation analysis.\nUsing the extracted data, perform local spatial autocorrelation analysis.\nUsing the extracted data, perform emerging hotspot analysis.\nDescribe the spatial patterns revealed by the analysis above."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#loading-of-packages",
    "href": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#loading-of-packages",
    "title": "In-class Exercise 7",
    "section": "Loading of Packages",
    "text": "Loading of Packages\n\n\nShow the code\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse, Kendall)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#geospatial",
    "href": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#geospatial",
    "title": "In-class Exercise 7",
    "section": "Geospatial",
    "text": "Geospatial\n\n\nShow the code\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `D:\\KrisLBT\\IS415-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#importing-apsatial-data",
    "href": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#importing-apsatial-data",
    "title": "In-class Exercise 7",
    "section": "Importing Apsatial Data",
    "text": "Importing Apsatial Data\n\n\nShow the code\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#deriving-the-spatial-weights",
    "href": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#deriving-the-spatial-weights",
    "title": "In-class Exercise 7",
    "section": "Deriving the spatial weights",
    "text": "Deriving the spatial weights\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\n\nShow the code\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n\n\n\nShow the code\nhead(GDPPC_nb)\n\n\n# A tibble: 6 × 5\n   Year County  GDPPC nb        wt       \n  <dbl> <chr>   <dbl> <list>    <list>   \n1  2005 Anxiang  8184 <int [6]> <dbl [6]>\n2  2005 Hanshou  6560 <int [6]> <dbl [6]>\n3  2005 Jinshi   9956 <int [5]> <dbl [5]>\n4  2005 Li       8394 <int [5]> <dbl [5]>\n5  2005 Linli    8850 <int [5]> <dbl [5]>\n6  2005 Shimen   9244 <int [6]> <dbl [6]>"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#computing-gi-1",
    "href": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#computing-gi-1",
    "title": "In-class Exercise 7",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\n\nShow the code\ngi_stars <- GDPPC_nb %>% \n  group_by(Year) %>% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %>% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#arrange-to-show-significant-emerging-hotcold-spots",
    "href": "In-class_Ex/In-class_Ex07/In_class_Ex07.html#arrange-to-show-significant-emerging-hotcold-spots",
    "title": "In-class Exercise 7",
    "section": "Arrange to show significant emerging hot/cold spots",
    "text": "Arrange to show significant emerging hot/cold spots\n\n\nShow the code\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html#importing-of-geospatial-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html#importing-of-geospatial-data",
    "title": "Take Home Exercise 02",
    "section": "Importing of Geospatial Data",
    "text": "Importing of Geospatial Data\nNow, we will import the map of Tainan.\n\n\nShow the code\ntainan_vil <- st_read(dsn='data/geospatial',\n                 layer = \"TAINAN_VILLAGE\")\n\n\nReading layer `TAINAN_VILLAGE' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n\n\nWe notice that instead of WGS84, the data is in TWD97. This is Taiwan’s own projected coordinate system.\nNow, I will plot out the map of Tainan Village\n\n\nShow the code\nplot(tainan_vil[\"COUNTYCODE\"])"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html#importing-of-aspatial-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html#importing-of-aspatial-data",
    "title": "Take Home Exercise 02",
    "section": "Importing of Aspatial Data",
    "text": "Importing of Aspatial Data\nNow, I will be using read_csv() to import the aspatial data (in csv format) into my R environment\n\n\nShow the code\ndengue <- read_csv(\"data/aspatial/Dengue_Daily.csv\")\n\n\nWe can check the content of dengue using the following code chunk:\n\n\nShow the code\nlist(dengue)\n\n\n[[1]]\n# A tibble: 106,861 × 26\n   發病日     個案研判日 通報日     性別  年齡層 居住縣市 居住鄉鎮 居住村里\n   <date>     <chr>      <date>     <chr> <chr>  <chr>    <chr>    <chr>   \n 1 1998-01-02 None       1998-01-07 男    40-44  屏東縣   屏東市   None    \n 2 1998-01-03 None       1998-01-14 男    30-34  屏東縣   東港鎮   None    \n 3 1998-01-13 None       1998-02-18 男    55-59  宜蘭縣   宜蘭市   None    \n 4 1998-01-15 None       1998-01-23 男    35-39  高雄市   苓雅區   None    \n 5 1998-01-20 None       1998-02-04 男    55-59  宜蘭縣   五結鄉   None    \n 6 1998-01-22 None       1998-02-19 男    20-24  桃園市   蘆竹區   None    \n 7 1998-01-23 None       1998-02-02 男    40-44  新北市   新店區   None    \n 8 1998-01-26 None       1998-02-19 女    65-69  台北市   北投區   None    \n 9 1998-02-11 None       1998-02-13 女    25-29  台南市   南區     None    \n10 1998-02-16 None       1998-02-24 男    20-24  高雄市   楠梓區   None    \n# ℹ 106,851 more rows\n# ℹ 18 more variables: 最小統計區 <chr>, 最小統計區中心點X <chr>,\n#   最小統計區中心點Y <chr>, 一級統計區 <chr>, 二級統計區 <chr>,\n#   感染縣市 <chr>, 感染鄉鎮 <chr>, 感染村里 <chr>, 是否境外移入 <chr>,\n#   感染國家 <chr>, 確定病例數 <dbl>, 居住村里代碼 <chr>, 感染村里代碼 <chr>,\n#   血清型 <chr>, 內政部居住縣市代碼 <chr>, 內政部居住鄉鎮代碼 <chr>,\n#   內政部感染縣市代碼 <chr>, 內政部感染鄉鎮代碼 <chr>\n\n\nThe column names of interest are “通報日” (TL: date), “最小統計區中心點X” (TL: x-coordinate), “最小統計區中心點Y” (TL: y-coordinate).\nWe notice that the data in dengue does not list the county name and instead only provides the coordinates of the dengue case. This suggests that we cannot use table joins and we will need to find the points that fall within the specific districts of Tainan Village.\nThere are also some rows that have None values in the x- and y- coordinates.We can exclude them using the following code chunk:\n\n\nShow the code\n# the None values are a character type so need to omit rows where either 最小統計區中心點X or 最小統計區中心點Y is \"None\"\ndengue <- dengue[!(dengue$最小統計區中心點X == \"None\" | dengue$最小統計區中心點Y == \"None\"), ]\n\n\nWe also notice that the coordinates in “最小統計區中心點X” and “最小統計區中心點Y” are in projected coordinates system. For now, it is unclear whether this is under the WGS84 coordinate system or TWD97. We will proceed with the assumption that it is in TWD97.\nAnother issue is that we need to analyse the dengue cases from specific weeks 31-50 in 2023 and the dengue contins cases from 1998 and in YMD format. To restrict this, we can also run the following code chunk:\n\n\nShow the code\n# get the ones from 2023\ndengue$epiweek <- epiweek(dengue$發病日)\ndengue$epiyear <- epiyear(dengue$發病日)\n\ndengue_2023 <- dengue[dengue$epiyear==2023,]\n\n# get only from weeks 31-50\ndengue_2023 <- dengue_2023[dengue_2023$epiweek>=31 & dengue_2023$epiweek<=50,]"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html#data-wrangling",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_02.html#data-wrangling",
    "title": "Take Home Exercise 02",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nCreating a simple feature data frame from aspatial data frame\nNow, I will use st_as_sf from the sf package to convert the dengue data frame into a simple feature data frame.\n\n\nShow the code\ndengue_sf <- st_as_sf(dengue,\n                      coords = c(\"最小統計區中心點X\",\"最小統計區中心點Y\"),\n                      crs = 3826)\n\n\n\n\nExtraction of Districts of Interest\n\n\nShow the code\nD01 <- tainan_vil %>%\n  filter(TOWNID==\"D01\") %>%\n  select()\n\nD02 <- tainan_vil %>%\n  filter(TOWNID==\"D02\") %>%\n  select()\n\nD04 <- tainan_vil %>%\n  filter(TOWNID==\"D04\") %>%\n  select()\n\nD06 <- tainan_vil %>%\n  filter(TOWNID==\"D06\") %>%\n  select()\n\nD07 <- tainan_vil %>%\n  filter(TOWNID==\"D07\") %>%\n  select()\n\nD08 <- tainan_vil %>%\n  filter(TOWNID==\"D08\") %>%\n  select()\n\nD32 <- tainan_vil %>%\n  filter(TOWNID==\"D32\") %>%\n  select()\n\nD39 <- tainan_vil %>%\n  filter(TOWNID==\"D39\") %>%\n  select()"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "From prof:\nAs a curious geospatial analytics green horn, you are interested to discover:\n\nif the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from space and space and time.\nIf the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\na study area layer in sf polygon features. It must be at village level and confined to the D01, D02, D04, D06, D07, D08, D32 and D39 counties of Tainan City, Taiwan.\na dengue fever layer within the study area in sf point features. The dengue fever cases should be confined to epidemiology week 31-50, 2023.\na derived dengue fever layer in spacetime s3 class of sfdep. It should contain, among many other useful information, a data field showing number of dengue fever cases by village and by epidemiology week.\n\nUsing the extracted data, perform global spatial autocorrelation analysis.\nUsing the extracted data, perform local spatial autocorrelation analysis.\nUsing the extracted data, perform emerging hotspot analysis.\nDescribe the spatial patterns revealed by the analysis above."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#importing-of-geospatial-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#importing-of-geospatial-data",
    "title": "Take Home Exercise 2",
    "section": "Importing of Geospatial Data",
    "text": "Importing of Geospatial Data\nI will be importing the tainan_vil data into my R environment using st_read() of the sf package.\n\n\nShow the code\ntainan_vil <- st_read(dsn = \"data/geospatial\",\n                  layer=\"TAINAN_VILLAGE\")\n\n\nReading layer `TAINAN_VILLAGE' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Take_Home_Exercises\\Take_Home_Exercise_2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#importing-of-aspatial-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#importing-of-aspatial-data",
    "title": "Take Home Exercise 2",
    "section": "Importing of Aspatial Data",
    "text": "Importing of Aspatial Data\nNow, I will be importing the daily dengue data into my R environment using the read_csv() function of the sf package.\n\n\nShow the code\ndengue <- read_csv(\"data/aspatial/Dengue_Daily.csv\")"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#getting-the-districts-of-interest",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#getting-the-districts-of-interest",
    "title": "Take Home Exercise 2",
    "section": "Getting the Districts of Interest",
    "text": "Getting the Districts of Interest\nFor the purposes of our analysis, we are only interested in the following districts:\n\nD01\nD02\nD04\nD06\nD07\nD08\nD32\nD39\n\n\n\nShow the code\n#getting the districts of interest\ndistricts = c(\"D01\",\"D02\",\"D04\",\"D06\",\"D07\",\"D08\",\"D32\",\"D39\")\n\n#restricting the village into just the required districts\ndistricts_sf = tainan_vil[tainan_vil$TOWNID %in% districts, ]\n\n\nHowever, we also face the problem of repeated village names in different towns. To fix this, we can specify the village name with the town name:\n\n\nShow the code\ndistricts_sf <- unite(districts_sf, VILLNAME, TOWNNAME, VILLNAME, sep = \"-\")"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#getting-the-dengue-cases-of-interest",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#getting-the-dengue-cases-of-interest",
    "title": "Take Home Exercise 2",
    "section": "Getting the Dengue Cases of Interest",
    "text": "Getting the Dengue Cases of Interest\nWe are also only interested in the dengue cases between weeks 31-50 in 2023. We can further restrict it using the following code chunk:\n\n\nShow the code\n# get the ones from 2023\ndengue$epiweek <- epiweek(dengue$發病日)\ndengue$epiyear <- epiyear(dengue$發病日)\n\ndengue <- dengue[dengue$epiyear==2023,]\n\n# get only from weeks 31-50\ndengue <- dengue[dengue$epiweek>=31 & dengue$epiweek<=50,]\n\n\nI also wanted to let the VILLNAME in dengue follow the same format as the VILLNAME in tainan_vil.\n\n\nShow the code\ndengue <- unite(dengue, VILLNAME, TOWNNAME, VILLNAME, sep = \"-\")\n\n\nWe can use the summary() function to investigate the contents of dengue\n\n\nShow the code\nsummary(dengue)\n\n\n     發病日            個案研判日            通報日          \n Min.   :2023-07-30   Length:25475       Min.   :2023-07-30  \n 1st Qu.:2023-09-11   Class :character   1st Qu.:2023-09-13  \n Median :2023-10-01   Mode  :character   Median :2023-10-03  \n Mean   :2023-10-03                      Mean   :2023-10-05  \n 3rd Qu.:2023-10-25                      3rd Qu.:2023-10-27  \n Max.   :2023-12-16                      Max.   :2023-12-23  \n     性別              年齡層           COUNTYNAME          VILLNAME        \n Length:25475       Length:25475       Length:25475       Length:25475      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  最小統計區        X-Coordinate       Y-Coordinate        一級統計區       \n Length:25475       Length:25475       Length:25475       Length:25475      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  二級統計區          感染縣市           感染鄉鎮           感染村里        \n Length:25475       Length:25475       Length:25475       Length:25475      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n 是否境外移入         感染國家           確定病例數 居住村里代碼      \n Length:25475       Length:25475       Min.   :1    Length:25475      \n Class :character   Class :character   1st Qu.:1    Class :character  \n Mode  :character   Mode  :character   Median :1    Mode  :character  \n                                       Mean   :1                      \n                                       3rd Qu.:1                      \n                                       Max.   :1                      \n 感染村里代碼          血清型          內政部居住縣市代碼 內政部居住鄉鎮代碼\n Length:25475       Length:25475       Length:25475       Length:25475      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n 內政部感染縣市代碼 內政部感染鄉鎮代碼    epiweek         epiyear    \n Length:25475       Length:25475       Min.   :31.00   Min.   :2023  \n Class :character   Class :character   1st Qu.:37.00   1st Qu.:2023  \n Mode  :character   Mode  :character   Median :40.00   Median :2023  \n                                       Mean   :39.96   Mean   :2023  \n                                       3rd Qu.:43.00   3rd Qu.:2023  \n                                       Max.   :50.00   Max.   :2023  \n\n\nLooking through the dataframe, I noticed that there are some “None” values in the X- and Y-coordinates. I will remove them using the following:\n\n\nShow the code\ndengue <- subset(dengue, `X-Coordinate` != \"None\" & \n                             `Y-Coordinate` != \"None\" &\n                             VILLNAME %in% districts_sf$VILLNAME)\n\nsum(dengue$`X-Coordinate` == \"None\")\n\n\n[1] 0\n\n\nFinally, I will be converting dengue into an sf object.\n\n\nShow the code\n# Create sf object after handling missing values\ndengue_sf <- st_as_sf(dengue, coords = c(\"X-Coordinate\", \"Y-Coordinate\"), crs = st_crs(districts_sf))"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#further-cleaning",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#further-cleaning",
    "title": "Take Home Exercise 2",
    "section": "Further Cleaning",
    "text": "Further Cleaning\nFor my own convenience, I decided to translate the columns in dengue from Traditional Chinese to English and also try to link them up the columns in counties_sf. The following code chunk was written to perform it:\n\n\nShow the code\ndengue <- dengue %>%\n  rename('X-Coordinate' = 最小統計區中心點X,\n         'Y-Coordinate' = 最小統計區中心點Y,\n         'COUNTYNAME' = 居住縣市,\n         'VILLNAME' = 居住村里,\n         'TOWNNAME' = 居住鄉鎮)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#conversion-of-dengue-to-sf",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#conversion-of-dengue-to-sf",
    "title": "Take Home Exercise 2",
    "section": "Conversion of dengue to sf",
    "text": "Conversion of dengue to sf\nWe can now convert dengue into an sf object.\n\n\nShow the code\ndengue_sf <- st_as_sf(dengue, coords = c('X-Coordinate','Y-Coordinate'), crs= st_crs(counties_sf))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#datasets-used",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#datasets-used",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Datasets Used",
    "text": "Datasets Used\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-packages",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Installing Packages",
    "text": "Installing Packages\nThe following packages will be used for this analysis:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\n\nShow the code\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-geospatial-datasets",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-geospatial-datasets",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Importing geospatial datasets",
    "text": "Importing geospatial datasets\n\n\nShow the code\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\KrisLBT\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe notice that it is in WGS84 instead of SVY21. We can correct it using the following:\n\n\nShow the code\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\nWe may now check if the CRS is correct.\n\n\nShow the code\nst_crs(mpsz_svy21)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nWe can also show the extent of mpsz by using st_bbox() of the sf package:\n\n\nShow the code\nst_bbox(mpsz_svy21) #view extent\n\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-aspatial-datasets",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-aspatial-datasets",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Importing Aspatial Datasets",
    "text": "Importing Aspatial Datasets\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\n\nShow the code\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\n\nShow the code\nglimpse(condo_resale)\n\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n\nShow the code\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\n\nShow the code\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\n\nShow the code\nsummary(condo_resale)\n\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\nConverting aspatial dataframe into an sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\n\nShow the code\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\n\nShow the code\nhead(condo_resale.sf)\n\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     <dbl>         <dbl>    <dbl> <dbl>    <dbl>          <dbl>            <dbl>\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA <dbl>, PROX_HAWKER_MARKET <dbl>,\n#   PROX_KINDERGARTEN <dbl>, PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "EDA using statistical graphics",
    "text": "EDA using statistical graphics\n\n\nShow the code\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\n\nShow the code\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nNow, we can plot the logged selling price.\n\n\nShow the code\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\nIt is now slightly less skewed than previously."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Multiple Histogram Plots distribution of variables",
    "text": "Multiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\n\nShow the code\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\nDrawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\n\nShow the code\ntmap_mode(\"view\")\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\nNow, I will create an interactive viewing map:\n\n\nShow the code\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntm_dots() is used instead of tm_bubbles\n\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nNow turn the R display into plot mode.\n\n\nShow the code\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Building Fixed Bandwidth GWR Model",
    "text": "Building Fixed Bandwidth GWR Model\n\nComputing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\n\nShow the code\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. It’s in metres because that’s the unit of measurement SVY21 is in.\n\n\nGWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\n\nShow the code\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\n\nShow the code\ngwr.fixed\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-02-25 11:05:46.98975 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-02-25 11:05:48.522928 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-adaptive-bandwith-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-adaptive-bandwith-gwr-model",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Building Adaptive Bandwith GWR Model",
    "text": "Building Adaptive Bandwith GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\nComputing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\n\nShow the code\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\nConstructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\n\nShow the code\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\nThe code below can be used to display the model output.\n\n\nShow the code\ngwr.adaptive\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-02-25 11:05:58.926952 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-02-25 11:06:00.399832 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-gwr-output",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Visualising GWR Output",
    "text": "Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-sdf-into-sf-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-sdf-into-sf-dataframe",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Converting SDF into sf dataframe",
    "text": "Converting SDF into sf dataframe\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\n\nShow the code\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\n\n\nShow the code\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\n\nShow the code\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\n\nShow the code\nglimpse(condo_resale.sf.adaptive)\n\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\nShow the code\nsummary(gwr.adaptive$SDF$yhat)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-local-r2",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Visualising local R2",
    "text": "Visualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\n\nShow the code\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-coefficient-estimates",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR",
    "section": "Visualising coefficient estimates",
    "text": "Visualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\n\nShow the code\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\n\nBy URA Planning Region\n\n\nShow the code\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#okay",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#okay",
    "title": "Take Home Exercise 2",
    "section": "okay",
    "text": "okay\n\n\nShow the code\ntainan_dengue <- left_join(counties_sf, dengueCountyComplete)\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(tainan_dengue) +\n  tm_fill(\"WEEKLY_DENGUE_CASE_NUM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"WEEKLY_DENGUE_CASE_NUM\") +\n  tm_layout(main.title = \"Distribution of case number per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\nI will now try and create the time series cube from dengue_county\n\n\nShow the code\ndengue_county_st <- spacetime(dengueCountyComplete, counties_sf,\n                              .loc_col=\"VILLNAME\",\n                              .time_col =\"epiweek\" )\n\n\nNext, is_spacetime_cube() will be used to verify if dengue_county_st is indeed a time series cube.\n\n\nShow the code\nis_spacetime_cube(dengue_county_st)\n\n\n[1] TRUE"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#preparation-of-data",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#preparation-of-data",
    "title": "Take Home Exercise 2",
    "section": "Preparation of Data",
    "text": "Preparation of Data\n\nJoining the Attribute Tables\nI will be joining districts_sf with dengueCountyComplete so we can analyse the global and local spatial autocorrelation.\n\n\nShow the code\ntainan_dengue <- left_join(districts_sf, dengueCountyComplete)\n\n\n\n\nVisualisation using a Choropleth map\nWe can visualise the distribution using a choropleth map:\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(tainan_dengue) +\n  tm_fill(\"WEEKLY_DENGUE_CASE_NUM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"WEEKLY_DENGUE_CASE_NUM\") +\n  tm_layout(main.title = \"Distribution of case number\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\nWe can also visualise this data according to month. For this, I will be using the month of September:\n\n\nShow the code\nsept <- tainan_dengue %>%\n  filter(epiweek>35 & epiweek<40)\ntmap_mode(\"plot\")\ntm_shape(tainan_dengue) +\n  tm_fill(\"WEEKLY_DENGUE_CASE_NUM\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"WEEKLY_DENGUE_CASE_NUM\") +\n  tm_layout(main.title = \"Distribution of case number in September\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\nWe notice that from the quantiles that it is very negatively skewed. As such, this suggests that there could be some clustering for the dengue cases.\n\n\nDeriving Contiguity weights: Queen’s Method\nWe will now derive the contiguity weights using the Queen’s method.\n\n\nShow the code\nwm_q <- tainan_dengue %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n\n\nWe can get a basic overview of wm_q using the following code chunk:\n\n\nShow the code\nwm_q\n\n\nSimple feature collection with 5160 features and 13 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\nFirst 10 features:\n                                                                                                                                                                                                                                                                                                                                                                                                                       nb\n1  2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n2  1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n3  1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n4  1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n5  1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n6  1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n7  1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n8  1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n9  1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n10  1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   wt\n1  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n2  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n3  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n4  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n5  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n6  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n7  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n8  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n9  0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n10 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823, 0.01265823\n      VILLCODE COUNTYNAME      VILLNAME      VILLENG COUNTYID COUNTYCODE TOWNID\n1  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n2  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n3  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n4  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n5  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n6  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n7  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n8  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n9  67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n10 67000350032     臺南市 安南區-青草里 Qingcao Vil.        D      67000    D06\n   TOWNCODE NOTE epiweek WEEKLY_DENGUE_CASE_NUM                       geometry\n1  67000350 <NA>      31                      0 POLYGON ((120.1176 23.08387...\n2  67000350 <NA>      32                      0 POLYGON ((120.1176 23.08387...\n3  67000350 <NA>      33                      0 POLYGON ((120.1176 23.08387...\n4  67000350 <NA>      34                      0 POLYGON ((120.1176 23.08387...\n5  67000350 <NA>      35                      0 POLYGON ((120.1176 23.08387...\n6  67000350 <NA>      36                      0 POLYGON ((120.1176 23.08387...\n7  67000350 <NA>      37                      1 POLYGON ((120.1176 23.08387...\n8  67000350 <NA>      38                      0 POLYGON ((120.1176 23.08387...\n9  67000350 <NA>      39                      0 POLYGON ((120.1176 23.08387...\n10 67000350 <NA>      40                      0 POLYGON ((120.1176 23.08387..."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#global-measure-of-spatial-autocorrelation",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#global-measure-of-spatial-autocorrelation",
    "title": "Take Home Exercise 2",
    "section": "Global Measure of Spatial Autocorrelation",
    "text": "Global Measure of Spatial Autocorrelation\n\nComputing Global Moran’s I Permutation Test\nAs opposed to a standard, Global Moran’s I test, a Global Moran’s I permutation test allows us to test if the data follows a random distribution by simulating many test, as opposed to just one.\nIt is alway a good practice to use set.seed() before performing simulation. This is to ensure that the computation is reproducible.\n\n\nShow the code\nset.seed(1234)\n\n\nNext, global_moran_perm() is used to perform Monte Carlo simulation. It will run 100 simulations.\n\n\nShow the code\nglobal_moran_perm(wm_q$WEEKLY_DENGUE_CASE_NUM,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.15977, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of dengue case resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering."
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#local-measure-of-spatial-autocorrelation",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#local-measure-of-spatial-autocorrelation",
    "title": "Take Home Exercise 2",
    "section": "Local Measure of Spatial Autocorrelation",
    "text": "Local Measure of Spatial Autocorrelation\n\nLocal Moran’s I\nIn this section,I will be computing the Local Moran’s I of tainan_dengue using local_moran().\n\n\nShow the code\nlisa <- wm_q %>% \n  mutate(local_moran = local_moran(\n    WEEKLY_DENGUE_CASE_NUM, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n\n\n\n\nVisualising Local Moran’s I\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of Dengue Cases\",\n            main.title.size = 0.8)\n\n\n\n\n\n\n\nVisualising Local Moran’s I and p-values\n\n\nShow the code\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I of Dengue Cases\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\nVisualising a LISA map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values.\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\n\nShow the code\nlisa_sig <- lisa  %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#creating-a-time-series-cube",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#creating-a-time-series-cube",
    "title": "Take Home Exercise 2",
    "section": "Creating a time-series cube",
    "text": "Creating a time-series cube\nI will now try and create the time series cube from dengueCountyComplete\n\n\nShow the code\ndengue_county_st <- spacetime(dengueCountyComplete, districts_sf,\n                              .loc_col=\"VILLNAME\",\n                              .time_col =\"epiweek\" )\n\n\nNext, is_spacetime_cube() will be used to verify if dengue_county_st is indeed a time series cube.\n\n\nShow the code\nis_spacetime_cube(dengue_county_st)\n\n\n[1] TRUE"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#computing-gi",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#computing-gi",
    "title": "Take Home Exercise 2",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\n\nShow the code\ndengue_county_nb <- dengue_county_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n\nWe can now visualise the head of dengue_county_nb\n\n\nShow the code\nhead(dengue_county_nb)\n\n\n# A tibble: 6 × 5\n  VILLNAME      epiweek WEEKLY_DENGUE_CASE_NUM nb        wt       \n  <chr>           <dbl>                  <dbl> <list>    <list>   \n1 安南區-青草里      31                      0 <int [4]> <dbl [4]>\n2 仁德區-保安里      31                      1 <int [6]> <dbl [6]>\n3 中西區-赤嵌里      31                      0 <int [9]> <dbl [9]>\n4 南區-大成里        31                      0 <int [7]> <dbl [7]>\n5 安南區-城北里      31                      0 <int [5]> <dbl [5]>\n6 安南區-城南里      31                      0 <int [8]> <dbl [8]>\n\n\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\n\nShow the code\ngi_stars <- dengue_county_nb %>% \n  group_by(epiweek) %>% \n  mutate(gi_star = local_gstar_perm(\n    WEEKLY_DENGUE_CASE_NUM, nb, wt)) %>% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#mann-kendall-test",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#mann-kendall-test",
    "title": "Take Home Exercise 2",
    "section": "Mann-Kendall Test",
    "text": "Mann-Kendall Test\nWe can now test the significance of the local Gi* for each location and plot it out.\n\n\nShow the code\nehsa <- gi_stars %>%\n  group_by(VILLNAME) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\n\nNow, we can arrange it to show significant hot/cold spots\n\n\nShow the code\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#performing-emerging-hotspot-analysis",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#performing-emerging-hotspot-analysis",
    "title": "Take Home Exercise 2",
    "section": "Performing Emerging Hotspot Analysis",
    "text": "Performing Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. dengue_county_sf), and the quoted name of the variable of interest (i.e. WEEKLY_DENGUE_CASE_NUM) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n\nShow the code\nehsa <- emerging_hotspot_analysis(\n  x = dengue_county_st, \n  .var = \"WEEKLY_DENGUE_CASE_NUM\", \n  k = 1, \n  nsim = 99\n)"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#visualising-the-distribution-of-ehsa-dates",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#visualising-the-distribution-of-ehsa-dates",
    "title": "Take Home Exercise 2",
    "section": "Visualising the distribution of EHSA dates",
    "text": "Visualising the distribution of EHSA dates\n\n\nShow the code\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))"
  },
  {
    "objectID": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#visualising-ehsa",
    "href": "Take_Home_Exercises/Take_Home_Exercise_2/Take_Home_Exercise_2.html#visualising-ehsa",
    "title": "Take Home Exercise 2",
    "section": "Visualising EHSA",
    "text": "Visualising EHSA\nNow that we know the distribution of the number and type of hot/cold spots in Tainan Village, we should also visualise it.\nBefore we do this, we must join districts_sf with ehsa.\n\n\nShow the code\ndistrict_ehsa <- districts_sf %>%\n  left_join(ehsa,\n            by = join_by(VILLNAME == location))\n\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\n\nShow the code\nehsa_sig <- district_ehsa  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"plot\")\ntm_shape(district_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  }
]