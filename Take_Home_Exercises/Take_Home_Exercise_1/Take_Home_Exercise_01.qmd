---
title: "Take Home Exercise 01"
format:
  html:
    code-fold: True
    code-summary: "Show the code"
    toc: True
    toc-depth: 4
execute:
  eval: True
  echo: True
  warning: False
date: "`r Sys.Date()`"
---

# Project Overview

In this take-home exercise, I will be finding the geographical and spatio-temporal distribution of Grab hailing service locations in Singapore.

The distribution will be analysed using the following, which will be displayed on the openstreetmap of Singapore:

-   Traditional Kernel Density Estimation (KDE) layers

-   Network Kernel Density Estimation (NKDE) or Temporal Network Kernel Density Estimation (TNKDE)

# Loading the packages

In this section, I will be loading the following packages:

-   maptools

-   sf

-   raster

-   spatstat

-   tmap

-   tidyverse

-   arrow

-   lubridate

-   spNetwork

-   classInt

-   viridis

```{r}
pacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse, arrow, lubridate, spNetwork, classInt)
```

# Traditional Kernel Density Estimation

## Extraction of the Coastal Outline of Mainland Singapore

Now, we can use the data for Singapore's outline. The data can be found on [data.gov.sg](data.gov.sg) and is the Master Plan Subzone Boundary 2014.

```{r}
mpsz_sf <- st_read(dsn = "../../data/data",
                layer = "MP14_SUBZONE_WEB_PL")
```

We have to check the CRS to ensure that it is in the correct coordinates system.

```{r}
#| eval: False
st_crs(mpsz_sf)
```

Since it is in the wrong CRS, we have to correct it to SVY21.

```{r}
mpsz_sf <- st_transform(mpsz_sf, 3414)
```

Now, we can plot the island.

```{r}
#| eval: False
plot(mpsz_sf)
```

We notice that the planning subzone includes areas where Grab does not serve due to lack of bridges. Hence, any roads in unavailable areas would either not be useful or actually distort the network analysis.

Most of the areas unserved by Grab are the outer islands. For this, we can identify which of the outer islands to exclude from our analysis.

```{r}
#| eval: False
outer_islands<-  filter(mpsz_sf, grepl('ISLAND', PLN_AREA_N))
plot(outer_islands["SUBZONE_N"])
```

However, we realise that not all the islands are unavailable to Grab drivers. Grab drivers are able to pick up and drop off at [Sentosa](https://www.sentosa.gov.sg/files/resources/news/20191121_media_release_sdc_grab_partnership.pdf).

Since 2019, Grab drivers have been allowed entry to [Jurong Island](https://www.grab.com/sg/driver/transport/jurong-island-security-pass-enrolment/), provided they have a security pass. However, given that very few drivers are allowed entry and the fact that this region is generally inaccessible to the public, we will be excluding them.

Hence, the islands we need to exclude are:

-   Semakau
-   Southern Group
-   Sudong
-   North-eastern Islands
-   Jurong Island and Bukom

```{r}
#| eval: False
serviced_area <- mpsz_sf %>%
  filter(!grepl("SEMAKAU|SOUTHERN GROUP|SUDONG|NORTH-EASTERN ISLANDS|JURONG ISLAND AND BUKOM", SUBZONE_N)) 
plot(serviced_area)
```

Now, we can blend away the boundaries.

```{r}
#| eval: False
sg_sf <- serviced_area %>%
  st_union()
```

Plot the sg_sf and we now see we have the CoastalOutline of Singapore.

```{r}
#| eval: False
plot(sg_sf)
```

We can save it as the CoastalOutline as a shapefile and read it again

```{r}
#| eval: false
# writing the CoastalOutline
st_write(sg_sf, 'data/CoastalOutline.shp')
```

```{r}
# reading the CoastalOutline
sg_sf <- st_read(dsn='data/',
                 layer = "CoastalOutline")
```

## Handling of the Grab Posisi data

### Reading the Grab Posisi Data

I will now be loading the Grab Posisi data

```{r}
#| eval: FALSE
df <- read_parquet(file="../../data/data/GrabPosisi/part-00000.snappy.parquet")
df1 <- read_parquet(file="../../data/data/GrabPosisi/part-00001.snappy.parquet")
df2 <- read_parquet(file="../../data/data/GrabPosisi/part-00002.snappy.parquet")
df3 <- read_parquet(file="../../data/data/GrabPosisi/part-00003.snappy.parquet")
df4 <- read_parquet(file="../../data/data/GrabPosisi/part-00004.snappy.parquet")
df5 <- read_parquet(file="../../data/data/GrabPosisi/part-00005.snappy.parquet")
df6 <- read_parquet(file="../../data/data/GrabPosisi/part-00006.snappy.parquet")
df7 <- read_parquet(file="../../data/data/GrabPosisi/part-00007.snappy.parquet")
df8 <- read_parquet(file="../../data/data/GrabPosisi/part-00008.snappy.parquet")
df9 <- read_parquet(file="../../data/data/GrabPosisi/part-00009.snappy.parquet")
```

### Handling the Grab Posisi data

#### Time stamp

There was supposed to be a datetime stamp but it wasn't in that format. As such, the data type needs to be changed.

```{r}
#| eval: FALSE
df$pingtimestamp <- as_datetime(df$pingtimestamp)
df1$pingtimestamp <- as_datetime(df1$pingtimestamp)
df2$pingtimestamp <- as_datetime(df2$pingtimestamp)
df3$pingtimestamp <- as_datetime(df3$pingtimestamp)
df4$pingtimestamp <- as_datetime(df4$pingtimestamp)
df5$pingtimestamp <- as_datetime(df5$pingtimestamp)
df6$pingtimestamp <- as_datetime(df6$pingtimestamp)
df7$pingtimestamp <- as_datetime(df7$pingtimestamp)
df8$pingtimestamp <- as_datetime(df8$pingtimestamp)
df9$pingtimestamp <- as_datetime(df9$pingtimestamp)
```

### Merging them into 1 data frame

#### Merging the origin data frames into 1 origin data frame

For easier handling, we can merge the data frames together.

```{r}
#| eval: False
origin_df_all <- df %>%
  rbind(df1) %>%
  rbind(df2) %>%
  rbind(df3) %>%
  rbind(df4) %>%
  rbind(df5) %>%
  rbind(df6) %>%
  rbind(df7) %>%
  rbind(df8) %>%
  rbind(df9)
```

### Extraction of origin and destination

#### Extraction of origin

Now, I will be extracting the origin.

The way I did it below is by performing the following steps

-   arrange it according to the trj_id (unique id determining where the person wants to at that point)
-   arranging it according to the time stamp (beginning and end)
-   getting the first row - mutating the data to weekday, start hour and the day

```{r}
#| eval: FALSE
origin_df <- origin_df_all %>%
  group_by(trj_id) %>%
  arrange(pingtimestamp) %>%
  filter(row_number()==1) %>%
  mutate(weekday = wday(pingtimestamp,
                        label=TRUE,
                        abbr=TRUE),
         start_hr= factor(hour(pingtimestamp)),
         day = factor(mday(pingtimestamp)))
```

##### Writing of origin data to rds

Now, I will write the origin data to rds for easier future handling.

```{r}
#| eval: False
write_rds(origin_df, "data/rds/origin_dfs.rds")
```

### Reading of RDS data

Now, we can clear the data in our environment and just read the rds data we saved.

#### Reading for origin data

```{r}
origin_df <- read_rds("data/rds/origin_dfs.rds")
```

## Analysis of Origins

### Visualising the Frequency Distribution

```{r}
ggplot(data=origin_df,
       aes(x=weekday)) +
  geom_bar()
```

As can be seen, the number of trips daily seem to be fairly equally distributed throughout the week.

### Visualising the Origins as a Point Map Symbol

We can visualise the geospatial distribution of the origin points.

```{r}
origins_sf <- st_as_sf(origin_df, coords = c("rawlng", "rawlat"),
                       crs=4326) %>%
  st_transform(crs=3414)
```

Now, we can visualise it using the code chunk below:

```{r}
tm_shape(mpsz_sf)+
  tm_polygons()+
tm_shape(origins_sf) +
  tm_dots()

```

### Convert sf data frames to sp's Spatial class

We can convert these data to sp's Spatial\* class and then convert into a generic sp format.

```{r}
sg <- as_Spatial(sg_sf)
mpsz <- as_Spatial(mpsz_sf)
origins <- as_Spatial(origins_sf) 
```

And into SpatialPolygon format

```{r}
sg_sp <- as(sg, "SpatialPolygons")
origins_sp <- as(origins, "SpatialPoints")
```

We then convert it to ppp format.

```{r}
origins_ppp <- as(origins_sp, "ppp")
origins_ppp
```

Now, I will plot origins_ppp.

```{r}
#| eval: False
plot(origins_ppp)
```

We must check for duplicates in the data using the code chunk below:

```{r}
any(duplicated(origins_ppp))
```

As there are no duplicates within the data, we do not have to apply any more transformation to the data.

### Create owin data

Now, we can convert the Coastal Outline to owin data and plot it out.

```{r}
sg_owin <- as(sg_sp, "owin")
plot(sg_owin)
```

### Combining events

We will now extract Grab origins within the Singapore CoastalOutline

```{r}
origins_SG_ppp = origins_ppp[sg_owin]
```

```{r}
plot(origins_SG_ppp)
```

## Traditional Kernel Analysis

Now we can begin the traditional kernel analysis

### Country level analysis

We can begin by trying to find all of the best kernel and bandwidths for the purposes of our analysis. To do this, we need to find the one with the tightest clusters.

In R, we have 4 possible kernel density bandwidths: diggle, ppl, scott and CvL. All of them will be test below:

```{r}
kde_origins_SG.bw <- density(origins_SG_ppp,
                              sigma=bw.diggle,
                              edge=TRUE,
                            kernel="gaussian") 
kde_origins_SG.ppl <- density(origins_SG_ppp, 
                               sigma=bw.ppl, 
                               edge=TRUE,
                               kernel="gaussian")
kde_origins_SG.CvL <- density(origins_SG_ppp, 
                               sigma=bw.CvL, 
                               edge=TRUE,
                               kernel="gaussian")
kde_origins_SG.scott <- density(origins_SG_ppp, 
                               sigma=bw.scott, 
                               edge=TRUE,
                               kernel="gaussian")
```

We may also plot them out:

```{r}
par(mfrow=c(2,2))
plot(kde_origins_SG.bw)
plot(kde_origins_SG.ppl)
plot(kde_origins_SG.CvL)
plot(kde_origins_SG.scott)
```

Now, we can check for the tightness of these clusters:

```{r}
# tightness of diggle
bw.diggle(origins_SG_ppp)

# tightness of ppl
bw.ppl(origins_SG_ppp)

# tightness of CvL
bw.CvL(origins_SG_ppp)

# tightness of scott
bw.scott(origins_SG_ppp)

```

We can observe that the smallest sigma value is from diggle, suggesting that it has the tightest clusters of all the bandwidth. Hence, we will continue using diggle for this analysis.

We can also test for different kernels:

```{r}
par(mfrow=c(2,2))
plot(density(origins_SG_ppp, 
             sigma=bw.diggle, 
             edge=TRUE, 
             kernel="gaussian"), 
     main="Gaussian")
plot(density(origins_SG_ppp, 
             sigma=bw.diggle, 
             edge=TRUE, 
             kernel="epanechnikov"), 
     main="Epanechnikov")
plot(density(origins_SG_ppp, 
             sigma=bw.diggle, 
             edge=TRUE, 
             kernel="quartic"), 
     main="Quartic")
plot(density(origins_SG_ppp, 
             sigma=bw.diggle, 
             edge=TRUE, 
             kernel="disc"), 
     main="Disc")

```

As they are identical, there is no need to choose a specific one.

### Regions of Interest

We can tighten our analysis to include only areas of interest. From the figures above, we observe higher densities in the planning areas Changi, Jurong East, Woodlands and Marine Parade, we can filter out *mpsz* to get them.

```{r}
# extraction of Changi Airport
CA = mpsz_sf[mpsz_sf$PLN_AREA_N=="CHANGI",]

# extraction of Jurong East
JE = mpsz_sf[mpsz_sf$PLN_AREA_N=="JURONG EAST",]

# extraction of Woodlands
WL = mpsz_sf[mpsz_sf$PLN_AREA_N=="WOODLANDS",]

# extraction of Marine Parade
MP = mpsz_sf[mpsz_sf$PLN_AREA_N=='MARINE PARADE',]
```

With this, we now have to perform the same functions we did in *Create Owin Data*.

```{r}
# turn them into spatial
CA_spatial <- as_Spatial(CA)
JE_spatial <- as_Spatial(JE)
WL_spatial <- as_Spatial(WL)
MP_spatial <- as_Spatial(MP)

# turn them into SpatialPolygons
CA_sp <- as(CA_spatial, "SpatialPolygons")
JE_sp <- as(JE_spatial, "SpatialPolygons")
WL_sp <- as(WL_spatial, "SpatialPolygons")
MP_sp <- as(MP_spatial, "SpatialPolygons")

# convert to owin

CA_owin = as(CA_sp, "owin")
JE_owin = as(JE_sp, "owin")
WL_owin = as(WL_sp, "owin")
MP_owin = as(MP_sp, "owin")
```

From here, we can extract the events that occurred in these planning areas.

```{r}
origins_CA_ppp = origins_SG_ppp[CA_owin]
origins_JE_ppp = origins_SG_ppp[JE_owin]
origins_WL_ppp = origins_SG_ppp[WL_owin]
origins_MP_ppp = origins_SG_ppp[MP_owin]
```

We can now perform the same analysis that we did above:

```{r}
kde_origins_CA <- density(origins_CA_ppp,
                              sigma=bw.diggle,
                              edge=TRUE,
                            kernel="gaussian") 
kde_origins_JE <- density(origins_JE_ppp,
                              sigma=bw.diggle,
                              edge=TRUE,
                            kernel="gaussian") 
kde_origins_WL <- density(origins_WL_ppp,
                              sigma=bw.diggle,
                              edge=TRUE,
                            kernel="gaussian") 
kde_origins_MP <- density(origins_MP_ppp,
                              sigma=bw.diggle,
                              edge=TRUE,
                            kernel="gaussian") 
```

We can also plot them out:

```{r}
par(mfrow=c(2,2))
plot(kde_origins_CA,
     main="Changi")
plot(kde_origins_WL,
     main="Woodlands")
plot(kde_origins_JE,
     main="Jurong East")
plot(kde_origins_MP,
     main="Marine Parade")
```

## Clark and Evans test

### Entire Singapore

```{r}
clarkevans.test(origins_SG_ppp,
                correction="none",
                clipregion="sg_owin",
                alternative=c("clustered"),
                nsim=99)
```

### Changi

```{r}
clarkevans.test(origins_CA_ppp,
                correction="none",
                clipregion=NULL,
                alternative=c("two.sided"),
                nsim=99)
```

### Woodlands

```{r}
clarkevans.test(origins_WL_ppp,
                correction="none",
                clipregion=NULL,
                alternative=c("two.sided"),
                nsim=99)
```

### Jurong East

```{r}
clarkevans.test(origins_JE_ppp,
                correction="none",
                clipregion=NULL,
                alternative=c("two.sided"),
                nsim=99)
```

### Marine Parade

```{r}
clarkevans.test(origins_MP_ppp,
                correction="none",
                clipregion=NULL,
                alternative=c("two.sided"),
                nsim=99)
```

# Network Kernel Density Estimation

While the above does show the distribution of the points and which areas are more concentrated than others, they do not account for the network of the roads. In this section, we will be finding the networks (roads) that are more densely used as origins points in Changi Airport and Marina East.

## Data Handling

### Handling of Road Data

Now, we can read the road data as provided by [openstreetmap](https://www.openstreetmap.org/). Note that it provides data for Malaysia, Singapore and Brunei all at once.

```{r}
#| eval: False
all_roads <- st_read(dsn='../../data/data/data',
                     layer = 'gis_osm_roads_free_1')
```

We realise that it is in WGS 84, not in SVY21 so we have to transform the data.

```{r}
#| eval: False
all_roads <- st_transform(all_roads, 3414)
```

We can check the CRS again for all_roads.

```{r}
#| eval: False
st_crs(all_roads)
```

Since we're only interested in the roads in mainland Singapore, we have to filter the roads.

```{r}
#| eval: False
SG_roads <- st_intersection(all_roads, sg_sf)
```

```{r}
#| eval: False
st_write(SG_roads, 'data/SG_roads.shp')
```

We can now read it from here.

```{r}
SG_roads <- st_read(dsn='data', layer= 'SG_roads')
```

### Getting the Roads within the Subzones

Now, we can find the streets that exist only inside the subzones.

```{r}
CA_roads <- st_intersection(SG_roads, CA)
WL_roads <- st_intersection(SG_roads, WL)
JE_roads <- st_intersection(SG_roads, JE)
MP_roads <- st_intersection(SG_roads, MP)
```

```{r}
CA_roads
WL_roads
JE_roads
MP_roads
```

We notice that all of the above are geometry type geometry and not a linestring. We can convert them with the following code chunk:

```{r}
#| warnings: False
CA_roads <- CA_roads %>%
  st_cast("LINESTRING")

WL_roads <- WL_roads %>%
  st_cast("LINESTRING")

JE_roads <- JE_roads %>%
  st_cast("LINESTRING")

MP_roads <- MP_roads %>%
  st_cast("LINESTRING")
```

### Extraction of the Events Within the Subzones

Before we can conduct analysis on the network, we will also need to constrict the events to exclusively the ones that occurred within these two subzones.

```{r}
#extraction of origin events that occurred within Changi and Marine Parade
CA_origins <- st_intersection(origins_sf, CA)
WL_origins <- st_intersection(origins_sf, WL)
JE_origins <- st_intersection(origins_sf, JE)
MP_origins <- st_intersection(origins_sf, MP)

```

We can now plot this data. In this instance, we can use Changi as an example:

```{r}
tmap_mode('view')
tm_shape(CA_origins)+
  tm_dots() +
  tm_shape(CA_roads) +
  tm_lines()
tmap_mode('plot')
```

## **Network Constrained KDE (NetKDE) Analysis**

### Preparing the lixel objects

We can now prepare the lixel objects.

```{r}
CA_lixels <- lixelize_lines(CA_roads, 
                         750, 
                         mindist = 375)
WL_lixels <- lixelize_lines(WL_roads, 
                         750, 
                         mindist = 375)
JE_lixels <- lixelize_lines(JE_roads, 
                         750, 
                         mindist = 375)
MP_lixels <- lixelize_lines(MP_roads, 
                         750, 
                         mindist = 375)
```

### Generating Line Points

```{r}
CA_samples <- lines_center(CA_lixels)
WL_samples <- lines_center(WL_lixels)
JE_samples <- lines_center(JE_lixels)
MP_samples <- lines_center(MP_lixels)
```

### Performing NetKDE

```{r}
CA_densities <- nkde(CA_roads, 
                  events = CA_origins,
                  w = rep(1,nrow(CA_origins)),
                  samples = CA_samples,
                  kernel_name = "quartic",
                  bw = 3.407207, 
                  div= "bw", 
                  method = "simple", 
                  digits = 1, 
                  tol = 1,
                  grid_shape = c(1,1), 
                  max_depth = 8,
                  agg = 10, #we aggregate events within a 10m radius (faster calculation)
                  sparse = TRUE,
                  verbose = FALSE)
# care about bw (bandwith) and kernel_name 
```
