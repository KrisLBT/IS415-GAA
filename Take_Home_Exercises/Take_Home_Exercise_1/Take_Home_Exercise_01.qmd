---
title: "Take Home Exercise 01: Part 1"
format:
  html:
    code-fold: True
    code-summary: "Show the code"
    toc: True
    toc-depth: 4
execute:
  eval: True
  echo: True
  warning: False
date: "`r Sys.Date()`"
---

# Project Overview

It is important for local and government urban planners to know and understand how, where and when people move. For Singapore, data regarding human mobility has largely been collected and disseminated by the Land Transport Authority (LTA). However, they have only collected and publicised data regarding passenger volume from trains stations and bus stops. While immensely helpful, it still leaves out crucial information about human mobility through other means of transport, making it incomphrensive.

In 2020, Grab released Grab Posisi, a data set regarding the origin and destinations of Grab taxi users in Singapore.

In this take-home exercise, I will be finding the geographical and spatio-temporal distribution of Grab hailing service locations in Singapore.

The distribution will be analysed using the following, which will be displayed on the openstreetmap of Singapore:

-   Traditional Kernel Density Estimation (KDE) layers: to analyse the where origin points tend to cluster

-   Network Kernel Density Estimation (NKDE): to analyse the clusters of origin points, as constrained by the road.

# Section Overview

In this section, I will be performing the EDA and data handling. Part 2 will be dealing with the traditional kernel density estimation and network kernel density estimation.

# The Data

| Name                 | Description                                                | Format   | Source                                                                                   |
|-----------------|-----------------|-----------------|-----------------------|
| MP14_SUBZONE_WEB_PL  | Subzone Boundary of Singapore (2014)                       | .shp     | [data.gov.sg](https://beta.data.gov.sg/datasets/d_d14da225fccf921049ab64238ff473d9/view) |
| Grab Posisi          | Dataframe of Origin and Destination Locations through Grab | .parquet | Provided by professor                                                                    |
| gis_osm_roads_free_1 | Road network of Malaysia, Singapore and Brunei             | .shp     | [geofabrik.de](https://download.geofabrik.de/asia/malaysia-singapore-brunei.html)        |

: Data Sets Used

# Loading the packages

In this section, I will be loading the following packages:

-   maptools

-   sf

-   raster

-   spatstat

-   tmap

-   tidyverse

-   arrow

-   lubridate

-   spNetwork

-   classInt

-   viridis

```{r}
pacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse, arrow, lubridate, spNetwork, classInt)
```

# General Handling

## Extraction of the Coastal Outline of Mainland Singapore

For the purposes of this analysis, we will also need to extract the Coastal Outline of Singapore. This is to create a boundary for all the points to fall under.

First, we need to read Singapore Master Plan Subzone 2014 to get Singapore's shape overall.

```{r}
mpsz_sf <- st_read(dsn = "../../data/data",
                layer = "MP14_SUBZONE_WEB_PL")
```

We have to check the CRS to ensure that it is in the correct coordinates system.

```{r}
#| eval: False
st_crs(mpsz_sf)
```

Since it is in the wrong CRS (WGS84), we have to correct it to SVY21.

```{r}
mpsz_sf <- st_transform(mpsz_sf, 3414)
```

Now, we can plot the island.

```{r}
#| eval: False
plot(mpsz_sf)
```

We notice that the planning subzone includes areas where Grab does not serve due to lack of bridges. Hence, any roads in unavailable areas would either not be useful or actually distort the network analysis.

Most of the areas unserved by Grab are the outer islands. For this, we can identify which of the outer islands to exclude from our analysis.

```{r}
#| eval: False
outer_islands<-  filter(mpsz_sf, grepl('ISLAND', PLN_AREA_N))
plot(outer_islands["SUBZONE_N"])
```

However, we realise that not all the islands are unavailable to Grab drivers. Grab drivers are able to pick up and drop off at [Sentosa](https://www.sentosa.gov.sg/files/resources/news/20191121_media_release_sdc_grab_partnership.pdf).

Since 2019, Grab drivers have been allowed entry to [Jurong Island](https://www.grab.com/sg/driver/transport/jurong-island-security-pass-enrolment/), provided they have a security pass. However, given that very few drivers are allowed entry and the fact that this region is generally inaccessible to the public, we will be excluding them.

Hence, the islands we need to exclude are:

-   Semakau
-   Southern Group
-   Sudong
-   North-eastern Islands
-   Jurong Island and Bukom

```{r}
#| eval: False
serviced_area <- mpsz_sf %>%
  filter(!grepl("SEMAKAU|SOUTHERN GROUP|SUDONG|NORTH-EASTERN ISLANDS|JURONG ISLAND AND BUKOM", SUBZONE_N)) 
plot(serviced_area)
```

Now, we can blend away the boundaries.

```{r}
#| eval: False
sg_sf <- serviced_area %>%
  st_union()
```

Plot the sg_sf and we now see we have the CoastalOutline of Singapore that is served by Grab.

```{r}
#| eval: False
plot(sg_sf)
```

We can save it as the CoastalOutline as a shapefile and read it again

```{r}
#| eval: false
# writing the CoastalOutline
st_write(sg_sf, 'data/CoastalOutline.shp')

```

```{r}
# reading the CoastalOutline
sg_sf <- st_read(dsn='data/',
                 layer = "CoastalOutline")
```

## Handling of the Grab Posisi data

We will also have to handle the Grab Posisi data.

The data is quite large. As such, Grab has divided into 10 parquet files for easier distribution.

### Reading the Grab Posisi Data

I will now be loading the Grab Posisi data

```{r}
#| eval: FALSE
df <- read_parquet(file="../../data/data/GrabPosisi/part-00000.snappy.parquet")
df1 <- read_parquet(file="../../data/data/GrabPosisi/part-00001.snappy.parquet")
df2 <- read_parquet(file="../../data/data/GrabPosisi/part-00002.snappy.parquet")
df3 <- read_parquet(file="../../data/data/GrabPosisi/part-00003.snappy.parquet")
df4 <- read_parquet(file="../../data/data/GrabPosisi/part-00004.snappy.parquet")
df5 <- read_parquet(file="../../data/data/GrabPosisi/part-00005.snappy.parquet")
df6 <- read_parquet(file="../../data/data/GrabPosisi/part-00006.snappy.parquet")
df7 <- read_parquet(file="../../data/data/GrabPosisi/part-00007.snappy.parquet")
df8 <- read_parquet(file="../../data/data/GrabPosisi/part-00008.snappy.parquet")
df9 <- read_parquet(file="../../data/data/GrabPosisi/part-00009.snappy.parquet")
```

### Handling the Grab Posisi data

#### Time stamp

Upon investigating the file, I noticed that there was supposed to be a datetime stamp but it wasn't in that format. As such, the data type needs to be changed.

```{r}
#| eval: FALSE
df$pingtimestamp <- as_datetime(df$pingtimestamp)
df1$pingtimestamp <- as_datetime(df1$pingtimestamp)
df2$pingtimestamp <- as_datetime(df2$pingtimestamp)
df3$pingtimestamp <- as_datetime(df3$pingtimestamp)
df4$pingtimestamp <- as_datetime(df4$pingtimestamp)
df5$pingtimestamp <- as_datetime(df5$pingtimestamp)
df6$pingtimestamp <- as_datetime(df6$pingtimestamp)
df7$pingtimestamp <- as_datetime(df7$pingtimestamp)
df8$pingtimestamp <- as_datetime(df8$pingtimestamp)
df9$pingtimestamp <- as_datetime(df9$pingtimestamp)
```

#### Merging them into 1 data frame

I also noticed that the the same ride might actually have origin and destination points through multiple data frames. As such, we need to merge them before we can extract the origin points.

```{r}
#| eval: False
origin_df_all <- df %>%
  rbind(df1) %>%
  rbind(df2) %>%
  rbind(df3) %>%
  rbind(df4) %>%
  rbind(df5) %>%
  rbind(df6) %>%
  rbind(df7) %>%
  rbind(df8) %>%
  rbind(df9)
```

#### Extraction of Origin

Now, I will be extracting the origin.

The way I did it below is by performing the following steps

-   arrange it according to the trj_id (unique id determining where the person wants to at that point)
-   arranging it according to the time stamp (beginning and end)
-   getting the first row - mutating the data to weekday, start hour and the day

```{r}
#| eval: FALSE
origin_df <- origin_df_all %>%
  group_by(trj_id) %>%
  arrange(pingtimestamp) %>%
  filter(row_number()==1) %>%
  mutate(weekday = wday(pingtimestamp,
                        label=TRUE,
                        abbr=TRUE),
         start_hr= factor(hour(pingtimestamp)),
         day = factor(mday(pingtimestamp)))
```

##### Writing of Origin Data to RDS

Now, I will write the origin data to rds for easier future handling.

```{r}
#| eval: False
write_rds(origin_df, "data/rds/origin_dfs.rds")
```

##### Reading of RDS data

Now, we can clear the data in our environment and just read the rds data we saved.

```{r}
origin_df <- read_rds("data/rds/origin_dfs.rds")
```

## Exploratory Data Analysis and Handling of Origins

In this section, I will be exploring the general distribution of the origin points and handling it for the subsequent sections, which will analyse the data in greater detail.

### Visualising the Frequency Distribution

First, I will plot out the general distribution of the origin points

```{r}
ggplot(data=origin_df,
       aes(x=weekday)) +
  geom_bar()
```

As can be seen, the number of trips daily seem to be fairly equally distributed throughout the week.

### Visualising the Origins as a Point Map Symbol

We can visualise the geospatial distribution of the origin points. First, we need to convert the coordinates to lat-long and transform it to the correct CRS.

```{r}
origins_sf <- st_as_sf(origin_df, coords = c("rawlng", "rawlat"),
                       crs=4326) %>%
  st_transform(crs=3414)
```

Now, we can visualise it using the code chunk below:

```{r}
#| eval: False
tm_shape(mpsz_sf)+
  tm_polygons()+
tm_shape(origins_sf) +
  tm_dots()

```

### Handling

For further analysis, we will need to convert the various data into different formats. These will be explained and performed in the code chunk below

```{r}
#conversion of sg_sf, mpsz_sf and origins_sf to a generic spatial class
sg <- as_Spatial(sg_sf)
mpsz <- as_Spatial(mpsz_sf)
origins <- as_Spatial(origins_sf) 

# Conversion of sg and origins to SpatialPolygon format
sg_sp <- as(sg, "SpatialPolygons")
origins_sp <- as(origins, "SpatialPoints")

# conversion of origins to ppp format
origins_ppp <- as(origins_sp, "ppp")
origins_ppp
```

Now, I will plot origins_ppp.

```{r}
#| eval: False
plot(origins_ppp)
```

We must check for duplicates in the data using the code chunk below:

```{r}
any(duplicated(origins_ppp))
```

As there are no duplicates within the data, we do not have to apply any more transformation to the data.

#### Create Owin Data

Now, we can convert the Coastal Outline to owin data and plot it out.

```{r}
sg_owin <- as(sg_sp, "owin")
plot(sg_owin)
```

#### Combining Events

We will now extract Grab origins within the Singapore CoastalOutline

```{r}
origins_SG_ppp = origins_ppp[sg_owin]

# plotting the distribution of the origins
plot(origins_SG_ppp)
```
